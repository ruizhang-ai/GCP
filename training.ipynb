{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading vectors from data/combined.vector\n",
      "Found 9493 vectors in data/combined.vector\n",
      "Processed 9000 vectors (94.81 %)\n",
      "Saving word vectors in data/word2vec.en.npy\n",
      "\n"
     ]
    }
   ],
   "source": [
    "! python utils/preprocess_text_word_vectors.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import cPickle\n",
    "train_dataset = cPickle.load(open('data/webnlg/train_data.pickle', 'rb'))\n",
    "dev_dataset = cPickle.load(open('data/webnlg/dev_data.pickle', 'rb'))\n",
    "test_dataset = cPickle.load(open('data/webnlg/test_data.pickle', 'rb'))\n",
    "test_unseen_dataset = cPickle.load(open('data/webnlg/test_unseen.pickle', 'rb'))\n",
    "test_gkb_dataset = cPickle.load(open('data/gkb/test_data.pickle', 'rb'))\n",
    "\n",
    "''' ADDITIONAL '''\n",
    "#gkb_dataset = cPickle.load(open('data/gkb/train_data.pickle', 'rb'))\n",
    "dev_dataset = dev_dataset[:200]\n",
    "train_dataset += dev_dataset[200:]\n",
    "#train_dataset += gkb_dataset\n",
    "''' ADDITIONAL '''\n",
    "print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import utility\n",
    "from kitchen.text.converters import getwriter, to_bytes, to_unicode\n",
    "from kitchen.i18n import get_translation_object\n",
    "translations = get_translation_object('example')\n",
    "_ = translations.ugettext\n",
    "b_ = translations.lgettext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "encoder_model = 'GLSTM' # BLSTM, TLSTM, TCNN, GLSTM\n",
    "includeLabel = True # delexicalization\n",
    "triple_mode = 'graph' # single, graph\n",
    "auto_adaptive = True # attention model\n",
    "\n",
    "if triple_mode == 'single':\n",
    "    triple_max_len = 20\n",
    "    input_max_len = 140\n",
    "    output_max_len = 70\n",
    "elif triple_mode == 'graph':\n",
    "    triple_max_len = 5\n",
    "    input_max_len = 140\n",
    "    output_max_len = 70"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "utility.createDataset(train_dataset, \"train\", triple_mode, includeLabel, triple_max_len, 'w')\n",
    "utility.createDataset(dev_dataset, \"dev\", triple_mode, includeLabel, triple_max_len, 'a')\n",
    "utility.createDataset(test_dataset, \"test\", triple_mode, includeLabel, triple_max_len, 'a')\n",
    "utility.createDataset(test_unseen_dataset, \"test_unseen\", triple_mode, includeLabel, triple_max_len, 'a')\n",
    "utility.createDataset(test_gkb_dataset, \"test_gkb\", triple_mode, includeLabel, triple_max_len, 'a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "Using cuDNN version 6021 on context None\n",
      "Mapped name None to device cuda0: Tesla K40c (0000:03:00.0)\n"
     ]
    }
   ],
   "source": [
    "from keras_wrapper.dataset import Dataset, saveDataset\n",
    "from data_engine.prepare_data import keep_n_captions\n",
    "ds = Dataset('GKB_Data', 'gkb', silence=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[01/10/2019 18:44:06] \tApplying tokenization function: \"tokenize_none\".\n",
      "[01/10/2019 18:44:07] Creating vocabulary for data with id 'all_vocab'.\n",
      "[01/10/2019 18:44:09] \t Total: 9516 unique words in 83124 sentences with a total of 2434451 words.\n",
      "[01/10/2019 18:44:09] Creating dictionary of 30000 most common words, covering 100.0% of the text.\n",
      "[01/10/2019 18:44:09] Loaded \"train\" set inputs of type \"text\" with id \"all_vocab\" and length 0.\n",
      "[01/10/2019 18:44:09] \tApplying tokenization function: \"tokenize_none\".\n",
      "[01/10/2019 18:44:09] \tReusing vocabulary named \"all_vocab\" for data with id \"target_text\".\n",
      "[01/10/2019 18:44:09] Loaded \"train\" set outputs of type \"text\" with id \"target_text\" and length 34653.\n",
      "[01/10/2019 18:44:09] \tApplying tokenization function: \"tokenize_none\".\n",
      "[01/10/2019 18:44:09] Loaded \"val\" set outputs of type \"text\" with id \"target_text\" and length 200.\n",
      "[01/10/2019 18:44:09] \tApplying tokenization function: \"tokenize_none\".\n",
      "[01/10/2019 18:44:10] \tReusing vocabulary named \"all_vocab\" for data with id \"source_text\".\n",
      "[01/10/2019 18:44:10] Loaded \"train\" set inputs of type \"text\" with id \"source_text\" and length 34653.\n",
      "[01/10/2019 18:44:10] \tApplying tokenization function: \"tokenize_none\".\n",
      "[01/10/2019 18:44:10] Loaded \"val\" set inputs of type \"text\" with id \"source_text\" and length 200.\n",
      "[01/10/2019 18:44:10] \tApplying tokenization function: \"tokenize_none\".\n",
      "[01/10/2019 18:44:10] \tReusing vocabulary named \"all_vocab\" for data with id \"state_below\".\n",
      "[01/10/2019 18:44:10] Loaded \"train\" set inputs of type \"text\" with id \"state_below\" and length 34653.\n",
      "[01/10/2019 18:44:10] Loaded \"val\" set inputs of type \"ghost\" with id \"state_below\" and length 200.\n",
      "[01/10/2019 18:44:10] Keeping 1 captions per input on the val set.\n",
      "[01/10/2019 18:44:10] Samples reduced to 200 in val set.\n",
      "[01/10/2019 18:44:10] <<< Saving Dataset instance to datasets/Dataset_GKB_Data.pkl ... >>>\n",
      "[01/10/2019 18:44:10] <<< Dataset instance saved >>>\n"
     ]
    }
   ],
   "source": [
    "ds.setInput('data/vocab.used',\n",
    "            'train',\n",
    "            type='text',\n",
    "            id='all_vocab',\n",
    "            required=False,\n",
    "            tokenization='tokenize_none',\n",
    "            pad_on_batch=False,\n",
    "            build_vocabulary=True,\n",
    "            offset=1,\n",
    "            fill='end',\n",
    "            max_text_len=output_max_len,\n",
    "            max_words=30000)\n",
    "ds.setOutput('data/train.tar',\n",
    "             'train',\n",
    "             type='text',\n",
    "             id='target_text',\n",
    "             tokenization='tokenize_none',\n",
    "             build_vocabulary='all_vocab',\n",
    "             pad_on_batch=False,\n",
    "             sample_weights=True,\n",
    "             max_text_len=output_max_len,\n",
    "             max_words=30000,\n",
    "             min_occ=0)\n",
    "\n",
    "ds.setOutput('data/dev.tar',\n",
    "             'val',\n",
    "             type='text',\n",
    "             id='target_text',\n",
    "             pad_on_batch=False,\n",
    "             tokenization='tokenize_none',\n",
    "             sample_weights=True,\n",
    "             max_text_len=output_max_len,\n",
    "             max_words=0)\n",
    "\n",
    "ds.setInput('data/train.src',\n",
    "            'train',\n",
    "            type='text',\n",
    "            id='source_text',\n",
    "            pad_on_batch=False,\n",
    "            tokenization='tokenize_none',\n",
    "            build_vocabulary='all_vocab',\n",
    "            fill='end',\n",
    "            max_text_len=input_max_len,\n",
    "            max_words=30000,\n",
    "            min_occ=0)\n",
    "ds.setInput('data/dev.src',\n",
    "            'val',\n",
    "            type='text',\n",
    "            id='source_text',\n",
    "            pad_on_batch=False,\n",
    "            tokenization='tokenize_none',\n",
    "            fill='end',\n",
    "            max_text_len=input_max_len,\n",
    "            min_occ=0)\n",
    "\n",
    "ds.setInput('data/train.tar',\n",
    "            'train',\n",
    "            type='text',\n",
    "            id='state_below',\n",
    "            required=False,\n",
    "            tokenization='tokenize_none',\n",
    "            pad_on_batch=False,\n",
    "            build_vocabulary='all_vocab',\n",
    "            offset=1,\n",
    "            fill='end',\n",
    "            max_text_len=output_max_len,\n",
    "            max_words=30000)\n",
    "ds.setInput(None,\n",
    "            'val',\n",
    "            type='ghost',\n",
    "            id='state_below',\n",
    "            required=False)\n",
    "\n",
    "keep_n_captions(ds, repeat=1, n=1, set_names=['val'])\n",
    "\n",
    "ds.vocabulary['source_text'] = ds.vocabulary['all_vocab']\n",
    "ds.vocabulary['state_below'] = ds.vocabulary['all_vocab']\n",
    "ds.vocabulary['target_text'] = ds.vocabulary['all_vocab']\n",
    "\n",
    "ds.vocabulary_len['source_text'] = ds.vocabulary_len['all_vocab']\n",
    "ds.vocabulary_len['state_below'] = ds.vocabulary_len['all_vocab']\n",
    "ds.vocabulary_len['target_text'] = ds.vocabulary_len['all_vocab']\n",
    "\n",
    "saveDataset(ds, 'datasets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[01/10/2019 18:44:10] Log file (/home/bayu/.picloud/cloud.log) opened\n",
      "[01/10/2019 18:44:11] <<< Loading Dataset instance from datasets/Dataset_GKB_Data.pkl ... >>>\n",
      "[01/10/2019 18:44:11] <<< Dataset instance loaded >>>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "source_text (InputLayer)        (None, 140)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               (None, 5)            0           source_text[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lambda_4 (Lambda)               (None, 5)            0           source_text[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "source_word_embedding (Embeddin (None, 5, 300)       2855700     lambda_2[0][0]                   \n",
      "                                                                 lambda_4[0][0]                   \n",
      "                                                                 lambda_6[0][0]                   \n",
      "                                                                 lambda_8[0][0]                   \n",
      "                                                                 lambda_10[0][0]                  \n",
      "                                                                 lambda_12[0][0]                  \n",
      "                                                                 lambda_14[0][0]                  \n",
      "                                                                 lambda_16[0][0]                  \n",
      "                                                                 lambda_18[0][0]                  \n",
      "                                                                 lambda_20[0][0]                  \n",
      "                                                                 lambda_22[0][0]                  \n",
      "                                                                 lambda_24[0][0]                  \n",
      "                                                                 lambda_26[0][0]                  \n",
      "                                                                 lambda_28[0][0]                  \n",
      "                                                                 lambda_30[0][0]                  \n",
      "                                                                 lambda_32[0][0]                  \n",
      "                                                                 lambda_34[0][0]                  \n",
      "                                                                 lambda_36[0][0]                  \n",
      "                                                                 lambda_38[0][0]                  \n",
      "                                                                 lambda_40[0][0]                  \n",
      "                                                                 lambda_42[0][0]                  \n",
      "                                                                 lambda_44[0][0]                  \n",
      "                                                                 lambda_46[0][0]                  \n",
      "                                                                 lambda_48[0][0]                  \n",
      "                                                                 lambda_50[0][0]                  \n",
      "                                                                 lambda_52[0][0]                  \n",
      "                                                                 lambda_54[0][0]                  \n",
      "                                                                 lambda_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_6 (Lambda)               (None, 5)            0           source_text[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)             (None, 1, 1500)      0           source_word_embedding[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "reshape_2 (Reshape)             (None, 1, 1500)      0           source_word_embedding[1][0]      \n",
      "__________________________________________________________________________________________________\n",
      "lambda_8 (Lambda)               (None, 5)            0           source_text[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 2, 1500)      0           reshape_1[0][0]                  \n",
      "                                                                 reshape_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_3 (Reshape)             (None, 1, 1500)      0           source_word_embedding[2][0]      \n",
      "__________________________________________________________________________________________________\n",
      "lambda_10 (Lambda)              (None, 5)            0           source_text[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 3, 1500)      0           concatenate_1[0][0]              \n",
      "                                                                 reshape_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_4 (Reshape)             (None, 1, 1500)      0           source_word_embedding[3][0]      \n",
      "__________________________________________________________________________________________________\n",
      "lambda_12 (Lambda)              (None, 5)            0           source_text[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 4, 1500)      0           concatenate_2[0][0]              \n",
      "                                                                 reshape_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_5 (Reshape)             (None, 1, 1500)      0           source_word_embedding[4][0]      \n",
      "__________________________________________________________________________________________________\n",
      "lambda_14 (Lambda)              (None, 5)            0           source_text[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 5, 1500)      0           concatenate_3[0][0]              \n",
      "                                                                 reshape_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_6 (Reshape)             (None, 1, 1500)      0           source_word_embedding[5][0]      \n",
      "__________________________________________________________________________________________________\n",
      "lambda_16 (Lambda)              (None, 5)            0           source_text[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 6, 1500)      0           concatenate_4[0][0]              \n",
      "                                                                 reshape_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_7 (Reshape)             (None, 1, 1500)      0           source_word_embedding[6][0]      \n",
      "__________________________________________________________________________________________________\n",
      "lambda_18 (Lambda)              (None, 5)            0           source_text[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 7, 1500)      0           concatenate_5[0][0]              \n",
      "                                                                 reshape_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_8 (Reshape)             (None, 1, 1500)      0           source_word_embedding[7][0]      \n",
      "__________________________________________________________________________________________________\n",
      "lambda_20 (Lambda)              (None, 5)            0           source_text[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, 8, 1500)      0           concatenate_6[0][0]              \n",
      "                                                                 reshape_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_9 (Reshape)             (None, 1, 1500)      0           source_word_embedding[8][0]      \n",
      "__________________________________________________________________________________________________\n",
      "lambda_22 (Lambda)              (None, 5)            0           source_text[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_8 (Concatenate)     (None, 9, 1500)      0           concatenate_7[0][0]              \n",
      "                                                                 reshape_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_10 (Reshape)            (None, 1, 1500)      0           source_word_embedding[9][0]      \n",
      "__________________________________________________________________________________________________\n",
      "lambda_24 (Lambda)              (None, 5)            0           source_text[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_9 (Concatenate)     (None, 10, 1500)     0           concatenate_8[0][0]              \n",
      "                                                                 reshape_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_11 (Reshape)            (None, 1, 1500)      0           source_word_embedding[10][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_26 (Lambda)              (None, 5)            0           source_text[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_10 (Concatenate)    (None, 11, 1500)     0           concatenate_9[0][0]              \n",
      "                                                                 reshape_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_12 (Reshape)            (None, 1, 1500)      0           source_word_embedding[11][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_28 (Lambda)              (None, 5)            0           source_text[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_11 (Concatenate)    (None, 12, 1500)     0           concatenate_10[0][0]             \n",
      "                                                                 reshape_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_13 (Reshape)            (None, 1, 1500)      0           source_word_embedding[12][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_30 (Lambda)              (None, 5)            0           source_text[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_12 (Concatenate)    (None, 13, 1500)     0           concatenate_11[0][0]             \n",
      "                                                                 reshape_13[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_14 (Reshape)            (None, 1, 1500)      0           source_word_embedding[13][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_32 (Lambda)              (None, 5)            0           source_text[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_13 (Concatenate)    (None, 14, 1500)     0           concatenate_12[0][0]             \n",
      "                                                                 reshape_14[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_15 (Reshape)            (None, 1, 1500)      0           source_word_embedding[14][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_34 (Lambda)              (None, 5)            0           source_text[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_14 (Concatenate)    (None, 15, 1500)     0           concatenate_13[0][0]             \n",
      "                                                                 reshape_15[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_16 (Reshape)            (None, 1, 1500)      0           source_word_embedding[15][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_36 (Lambda)              (None, 5)            0           source_text[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_15 (Concatenate)    (None, 16, 1500)     0           concatenate_14[0][0]             \n",
      "                                                                 reshape_16[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_17 (Reshape)            (None, 1, 1500)      0           source_word_embedding[16][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_38 (Lambda)              (None, 5)            0           source_text[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_16 (Concatenate)    (None, 17, 1500)     0           concatenate_15[0][0]             \n",
      "                                                                 reshape_17[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_18 (Reshape)            (None, 1, 1500)      0           source_word_embedding[17][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_40 (Lambda)              (None, 5)            0           source_text[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_17 (Concatenate)    (None, 18, 1500)     0           concatenate_16[0][0]             \n",
      "                                                                 reshape_18[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_19 (Reshape)            (None, 1, 1500)      0           source_word_embedding[18][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_42 (Lambda)              (None, 5)            0           source_text[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_18 (Concatenate)    (None, 19, 1500)     0           concatenate_17[0][0]             \n",
      "                                                                 reshape_19[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_20 (Reshape)            (None, 1, 1500)      0           source_word_embedding[19][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_44 (Lambda)              (None, 5)            0           source_text[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_19 (Concatenate)    (None, 20, 1500)     0           concatenate_18[0][0]             \n",
      "                                                                 reshape_20[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_21 (Reshape)            (None, 1, 1500)      0           source_word_embedding[20][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_46 (Lambda)              (None, 5)            0           source_text[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_20 (Concatenate)    (None, 21, 1500)     0           concatenate_19[0][0]             \n",
      "                                                                 reshape_21[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_22 (Reshape)            (None, 1, 1500)      0           source_word_embedding[21][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_48 (Lambda)              (None, 5)            0           source_text[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_21 (Concatenate)    (None, 22, 1500)     0           concatenate_20[0][0]             \n",
      "                                                                 reshape_22[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_23 (Reshape)            (None, 1, 1500)      0           source_word_embedding[22][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_50 (Lambda)              (None, 5)            0           source_text[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_22 (Concatenate)    (None, 23, 1500)     0           concatenate_21[0][0]             \n",
      "                                                                 reshape_23[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_24 (Reshape)            (None, 1, 1500)      0           source_word_embedding[23][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_52 (Lambda)              (None, 5)            0           source_text[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_23 (Concatenate)    (None, 24, 1500)     0           concatenate_22[0][0]             \n",
      "                                                                 reshape_24[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_25 (Reshape)            (None, 1, 1500)      0           source_word_embedding[24][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_54 (Lambda)              (None, 5)            0           source_text[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_24 (Concatenate)    (None, 25, 1500)     0           concatenate_23[0][0]             \n",
      "                                                                 reshape_25[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_26 (Reshape)            (None, 1, 1500)      0           source_word_embedding[25][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_56 (Lambda)              (None, 5)            0           source_text[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_25 (Concatenate)    (None, 26, 1500)     0           concatenate_24[0][0]             \n",
      "                                                                 reshape_26[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_27 (Reshape)            (None, 1, 1500)      0           source_word_embedding[26][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_26 (Concatenate)    (None, 27, 1500)     0           concatenate_25[0][0]             \n",
      "                                                                 reshape_27[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_28 (Reshape)            (None, 1, 1500)      0           source_word_embedding[27][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_27 (Concatenate)    (None, 28, 1500)     0           concatenate_26[0][0]             \n",
      "                                                                 reshape_28[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_29 (Reshape)            (None, 14, 3000)     0           concatenate_27[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "masking_1 (Masking)             (None, 14, 3000)     0           reshape_29[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) (None, 14, 1024)     8245248     masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "masking_2 (Masking)             (None, 14, 1024)     0           bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "state_below (InputLayer)        (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "masked_mean_1 (MaskedMean)      (None, 1024)         0           masking_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target_word_embedding (Embeddin (None, None, 300)    2855700     state_below[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "initial_state (Dense)           (None, 512)          524800      masked_mean_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "initial_memory (Dense)          (None, 512)          524800      masked_mean_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "state_below_gaussian_noise (Gau (None, None, 300)    0           target_word_embedding[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "initial_state_gaussian_noise (G (None, 512)          0           initial_state[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "initial_memory_gaussian_noise ( (None, 512)          0           initial_memory[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "state_below_batch_normalization (None, None, 300)    1200        state_below_gaussian_noise[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "initial_state_batch_normalizati (None, 512)          2048        initial_state_gaussian_noise[0][0\n",
      "__________________________________________________________________________________________________\n",
      "initial_memory_batch_normalizat (None, 512)          2048        initial_memory_gaussian_noise[0][\n",
      "__________________________________________________________________________________________________\n",
      "state_below_dropout (Dropout)   (None, None, 300)    0           state_below_batch_normalization[0\n",
      "__________________________________________________________________________________________________\n",
      "initial_state_dropout (Dropout) (None, 512)          0           initial_state_batch_normalization\n",
      "__________________________________________________________________________________________________\n",
      "initial_memory_dropout (Dropout (None, 512)          0           initial_memory_batch_normalizatio\n",
      "__________________________________________________________________________________________________\n",
      "decoder_AttConditionalLSTMCond  multiple             5600270     state_below_dropout[0][0]        \n",
      "                                                                 masking_2[0][0]                  \n",
      "                                                                 initial_state_dropout[0][0]      \n",
      "                                                                 initial_memory_dropout[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "proj_h0_gaussian_noise (Gaussia (None, None, 512)    0           decoder_AttConditionalLSTMCond[0]\n",
      "__________________________________________________________________________________________________\n",
      "proj_h0_batch_normalization (Ba (None, None, 512)    2048        proj_h0_gaussian_noise[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "proj_h0_dropout (Dropout)       (None, None, 512)    0           proj_h0_batch_normalization[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "permute_general_1 (PermuteGener multiple             0           decoder_AttConditionalLSTMCond[0]\n",
      "                                                                 logit_ctx[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "decoder_LSTMCond1 (LSTMCond)    [(None, None, 512),  4196352     proj_h0_dropout[0][0]            \n",
      "                                                                 permute_general_1[0][0]          \n",
      "                                                                 initial_state_dropout[0][0]      \n",
      "                                                                 initial_memory_dropout[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "proj_h1_gaussian_noise (Gaussia (None, None, 512)    0           decoder_LSTMCond1[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "proj_h1_batch_normalization (Ba (None, None, 512)    2048        proj_h1_gaussian_noise[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "proj_h1_dropout (Dropout)       (None, None, 512)    0           proj_h1_batch_normalization[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, None, 512)    0           proj_h0_dropout[0][0]            \n",
      "                                                                 proj_h1_dropout[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "logit_ctx (TimeDistributed)     (None, None, 300)    307500      decoder_AttConditionalLSTMCond[0]\n",
      "__________________________________________________________________________________________________\n",
      "logit_lstm (TimeDistributed)    (None, None, 300)    153900      add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "logit_emb (TimeDistributed)     (None, None, 300)    90300       state_below_dropout[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "out_layer_mlp_gaussian_noise (G (None, None, 300)    0           logit_lstm[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "out_layer_ctx_gaussian_noise (G (None, None, 300)    0           permute_general_1[1][0]          \n",
      "__________________________________________________________________________________________________\n",
      "out_layer_emb_gaussian_noise (G (None, None, 300)    0           logit_emb[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "out_layer_mlp_batch_normalizati (None, None, 300)    1200        out_layer_mlp_gaussian_noise[0][0\n",
      "__________________________________________________________________________________________________\n",
      "out_layer_ctx_batch_normalizati (None, None, 300)    1200        out_layer_ctx_gaussian_noise[0][0\n",
      "__________________________________________________________________________________________________\n",
      "out_layer_emb_batch_normalizati (None, None, 300)    1200        out_layer_emb_gaussian_noise[0][0\n",
      "__________________________________________________________________________________________________\n",
      "out_layer_mlp_dropout (Dropout) (None, None, 300)    0           out_layer_mlp_batch_normalization\n",
      "__________________________________________________________________________________________________\n",
      "out_layer_ctx_dropout (Dropout) (None, None, 300)    0           out_layer_ctx_batch_normalization\n",
      "__________________________________________________________________________________________________\n",
      "out_layer_emb_dropout (Dropout) (None, None, 300)    0           out_layer_emb_batch_normalization\n",
      "__________________________________________________________________________________________________\n",
      "additional_input (Add)          (None, None, 300)    0           out_layer_mlp_dropout[0][0]      \n",
      "                                                                 out_layer_ctx_dropout[0][0]      \n",
      "                                                                 out_layer_emb_dropout[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, None, 300)    0           additional_input[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "linear_0 (TimeDistributed)      (None, None, 300)    90300       activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "out_layer_linear_0_gaussian_noi (None, None, 300)    0           linear_0[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "out_layer_linear_0_batch_normal (None, None, 300)    1200        out_layer_linear_0_gaussian_noise\n",
      "__________________________________________________________________________________________________\n",
      "out_layer_linear_0_dropout (Dro (None, None, 300)    0           out_layer_linear_0_batch_normaliz\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target_text (TimeDistributed)   (None, None, 9519)   2865219     out_layer_linear_0_dropout[0][0] \n",
      "==================================================================================================\n",
      "Total params: 28,324,281\n",
      "Trainable params: 28,317,185\n",
      "Non-trainable params: 7,096\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from config import load_parameters\n",
    "from model_zoo import TranslationModel\n",
    "import utils\n",
    "from keras_wrapper.cnn_model import loadModel\n",
    "from keras_wrapper.dataset import loadDataset\n",
    "from keras_wrapper.extra.callbacks import PrintPerformanceMetricOnEpochEndOrEachNUpdates\n",
    "params = load_parameters()\n",
    "dataset = loadDataset('datasets/Dataset_GKB_Data.pkl')\n",
    "\n",
    "params['INPUT_VOCABULARY_SIZE'] = dataset.vocabulary_len['all_vocab']\n",
    "params['OUTPUT_VOCABULARY_SIZE'] = dataset.vocabulary_len['all_vocab']\n",
    "params['INPUT_MAX_LEN'] = input_max_len\n",
    "params['OUTPUT_MAX_LEN'] = output_max_len\n",
    "params['TRIPLE_MAX_LEN'] = triple_max_len\n",
    "params['ENCODER_MODEL'] = encoder_model\n",
    "params['AUTO_ADAPTIVE'] = auto_adaptive\n",
    "\n",
    "nmt_model = TranslationModel(params,\n",
    "                             model_type='GroundHogModel', \n",
    "                             model_name='tutorial_model',\n",
    "                             vocabularies=dataset.vocabulary,\n",
    "                             store_path='trained_models/gkb_model/',\n",
    "                             verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inputMapping = dict()\n",
    "for i, id_in in enumerate(params['INPUTS_IDS_DATASET']):\n",
    "    pos_source = dataset.ids_inputs.index(id_in)\n",
    "    id_dest = nmt_model.ids_inputs[i]\n",
    "    inputMapping[id_dest] = pos_source\n",
    "nmt_model.setInputsMapping(inputMapping)\n",
    "\n",
    "outputMapping = dict()\n",
    "for i, id_out in enumerate(params['OUTPUTS_IDS_DATASET']):\n",
    "    pos_target = dataset.ids_outputs.index(id_out)\n",
    "    id_dest = nmt_model.ids_outputs[i]\n",
    "    outputMapping[id_dest] = pos_target\n",
    "nmt_model.setOutputsMapping(outputMapping)\n",
    "\n",
    "extra_vars = {'language': 'en',\n",
    "              'n_parallel_loaders': 8,\n",
    "              'tokenize_f': eval('dataset.' + 'tokenize_none'),\n",
    "              'beam_size': 12,\n",
    "              'maxlen': output_max_len,\n",
    "              'model_inputs': ['source_text', 'state_below'],\n",
    "              'model_outputs': ['target_text'],\n",
    "              'dataset_inputs': ['source_text', 'state_below'],\n",
    "              'dataset_outputs': ['target_text'],\n",
    "              'normalize': True,\n",
    "              'alpha_factor': 0.6,\n",
    "              'val': {'references': dataset.extra_variables['val']['target_text']}\n",
    "              }\n",
    "\n",
    "vocab = dataset.vocabulary['all_vocab']['idx2words']\n",
    "callbacks = []\n",
    "callbacks.append(PrintPerformanceMetricOnEpochEndOrEachNUpdates(nmt_model,\n",
    "                                                                dataset,\n",
    "                                                                gt_id='target_text',\n",
    "                                                                metric_name=['coco'],\n",
    "                                                                set_name=['val'],\n",
    "                                                                batch_size=64,\n",
    "                                                                each_n_epochs=1,\n",
    "                                                                extra_vars=extra_vars,\n",
    "                                                                reload_epoch=0,\n",
    "                                                                is_text=True,\n",
    "                                                                index2word_y=vocab,\n",
    "                                                                sampling_type='max_likelihood',\n",
    "                                                                beam_search=True,\n",
    "                                                                save_path=nmt_model.model_path,\n",
    "                                                                start_eval_on_epoch=0,\n",
    "                                                                write_samples=True,\n",
    "                                                                write_type='list',\n",
    "                                                                verbose=True))\n",
    "\n",
    "training_params = {'n_epochs': 50,\n",
    "                   'batch_size': 64,\n",
    "                   'maxlen': output_max_len,\n",
    "                   'epochs_for_save': 1,\n",
    "                   'verbose': 0,\n",
    "                   'eval_on_sets': [], \n",
    "                   'n_parallel_loaders': 16,\n",
    "                   'extra_callbacks': callbacks,\n",
    "                   'reload_epoch': 0,\n",
    "                   'epoch_offset': 0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[01/10/2019 18:44:26] WARNING: parallel loaders are not implemented\n",
      "ERROR (theano.gof.opt): SeqOptimizer apply <theano.scan_module.scan_opt.PushOutScanOutput object at 0x7feb65de52d0>\n",
      "[01/10/2019 18:44:38] SeqOptimizer apply <theano.scan_module.scan_opt.PushOutScanOutput object at 0x7feb65de52d0>\n",
      "ERROR (theano.gof.opt): Traceback:\n",
      "[01/10/2019 18:44:38] Traceback:\n",
      "ERROR (theano.gof.opt): Traceback (most recent call last):\n",
      "  File \"/home/bayu/anaconda2/envs/gtrlstm_extension/lib/python2.7/site-packages/theano/gof/opt.py\", line 251, in apply\n",
      "    sub_prof = optimizer.optimize(fgraph)\n",
      "  File \"/home/bayu/anaconda2/envs/gtrlstm_extension/lib/python2.7/site-packages/theano/gof/opt.py\", line 97, in optimize\n",
      "    ret = self.apply(fgraph, *args, **kwargs)\n",
      "  File \"/home/bayu/anaconda2/envs/gtrlstm_extension/lib/python2.7/site-packages/theano/scan_module/scan_opt.py\", line 685, in apply\n",
      "    node = self.process_node(fgraph, node)\n",
      "  File \"/home/bayu/anaconda2/envs/gtrlstm_extension/lib/python2.7/site-packages/theano/scan_module/scan_opt.py\", line 745, in process_node\n",
      "    node, args)\n",
      "  File \"/home/bayu/anaconda2/envs/gtrlstm_extension/lib/python2.7/site-packages/theano/scan_module/scan_opt.py\", line 854, in push_out_inner_vars\n",
      "    add_as_nitsots)\n",
      "  File \"/home/bayu/anaconda2/envs/gtrlstm_extension/lib/python2.7/site-packages/theano/scan_module/scan_opt.py\", line 906, in add_nitsot_outputs\n",
      "    reason='scanOp_pushout_output')\n",
      "  File \"/home/bayu/anaconda2/envs/gtrlstm_extension/lib/python2.7/site-packages/theano/gof/toolbox.py\", line 569, in replace_all_validate_remove\n",
      "    chk = fgraph.replace_all_validate(replacements, reason)\n",
      "  File \"/home/bayu/anaconda2/envs/gtrlstm_extension/lib/python2.7/site-packages/theano/gof/toolbox.py\", line 543, in replace_all_validate\n",
      "    fgraph.validate()\n",
      "  File \"/home/bayu/anaconda2/envs/gtrlstm_extension/lib/python2.7/site-packages/theano/gof/toolbox.py\", line 434, in validate_\n",
      "    ret = fgraph.execute_callbacks('validate')\n",
      "  File \"/home/bayu/anaconda2/envs/gtrlstm_extension/lib/python2.7/site-packages/theano/gof/fg.py\", line 594, in execute_callbacks\n",
      "    fn(self, *args, **kwargs)\n",
      "  File \"/home/bayu/anaconda2/envs/gtrlstm_extension/lib/python2.7/site-packages/theano/gof/toolbox.py\", line 600, in validate\n",
      "    raise theano.gof.InconsistencyError(\"Trying to reintroduce a removed node\")\n",
      "InconsistencyError: Trying to reintroduce a removed node\n",
      "\n",
      "[01/10/2019 18:44:38] Traceback (most recent call last):\n",
      "  File \"/home/bayu/anaconda2/envs/gtrlstm_extension/lib/python2.7/site-packages/theano/gof/opt.py\", line 251, in apply\n",
      "    sub_prof = optimizer.optimize(fgraph)\n",
      "  File \"/home/bayu/anaconda2/envs/gtrlstm_extension/lib/python2.7/site-packages/theano/gof/opt.py\", line 97, in optimize\n",
      "    ret = self.apply(fgraph, *args, **kwargs)\n",
      "  File \"/home/bayu/anaconda2/envs/gtrlstm_extension/lib/python2.7/site-packages/theano/scan_module/scan_opt.py\", line 685, in apply\n",
      "    node = self.process_node(fgraph, node)\n",
      "  File \"/home/bayu/anaconda2/envs/gtrlstm_extension/lib/python2.7/site-packages/theano/scan_module/scan_opt.py\", line 745, in process_node\n",
      "    node, args)\n",
      "  File \"/home/bayu/anaconda2/envs/gtrlstm_extension/lib/python2.7/site-packages/theano/scan_module/scan_opt.py\", line 854, in push_out_inner_vars\n",
      "    add_as_nitsots)\n",
      "  File \"/home/bayu/anaconda2/envs/gtrlstm_extension/lib/python2.7/site-packages/theano/scan_module/scan_opt.py\", line 906, in add_nitsot_outputs\n",
      "    reason='scanOp_pushout_output')\n",
      "  File \"/home/bayu/anaconda2/envs/gtrlstm_extension/lib/python2.7/site-packages/theano/gof/toolbox.py\", line 569, in replace_all_validate_remove\n",
      "    chk = fgraph.replace_all_validate(replacements, reason)\n",
      "  File \"/home/bayu/anaconda2/envs/gtrlstm_extension/lib/python2.7/site-packages/theano/gof/toolbox.py\", line 543, in replace_all_validate\n",
      "    fgraph.validate()\n",
      "  File \"/home/bayu/anaconda2/envs/gtrlstm_extension/lib/python2.7/site-packages/theano/gof/toolbox.py\", line 434, in validate_\n",
      "    ret = fgraph.execute_callbacks('validate')\n",
      "  File \"/home/bayu/anaconda2/envs/gtrlstm_extension/lib/python2.7/site-packages/theano/gof/fg.py\", line 594, in execute_callbacks\n",
      "    fn(self, *args, **kwargs)\n",
      "  File \"/home/bayu/anaconda2/envs/gtrlstm_extension/lib/python2.7/site-packages/theano/gof/toolbox.py\", line 600, in validate\n",
      "    raise theano.gof.InconsistencyError(\"Trying to reintroduce a removed node\")\n",
      "InconsistencyError: Trying to reintroduce a removed node\n",
      "\n",
      "[01/10/2019 18:59:57] WARNING: parallel loaders are not implemented\n",
      "[01/10/2019 18:59:57] <<< Predicting outputs of val set >>>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sampling 200/200  -  ETA: 3s   \n",
      " Total cost of the translations: 2655.928583 \t Average cost of the translations: 13.279643\n",
      "The sampling took: 606.835282 secs (Speed: 3.034176 sec/sample)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[01/10/2019 19:10:04] Prediction output 0: target_text (text)\n",
      "[01/10/2019 19:10:04] Decoding beam search prediction ...\n",
      "[01/10/2019 19:10:04] Evaluating on metric coco\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[01/10/2019 19:10:14] Computing coco scores on the val split...\n",
      "[01/10/2019 19:10:14] Bleu_1: 0.446417650261\n",
      "[01/10/2019 19:10:14] Bleu_2: 0.256409387209\n",
      "[01/10/2019 19:10:14] Bleu_3: 0.154498678467\n",
      "[01/10/2019 19:10:14] Bleu_4: 0.099515784306\n",
      "[01/10/2019 19:10:14] CIDEr: 0.702420428765\n",
      "[01/10/2019 19:10:14] METEOR: 0.303670072197\n",
      "[01/10/2019 19:10:14] ROUGE_L: 0.440470827673\n",
      "[01/10/2019 19:10:14] TER: 0.700119474313\n",
      "[01/10/2019 19:10:14] Done evaluating on metric coco\n",
      "[01/10/2019 19:10:14] <<< Progress plot saved in trained_models/gkb_model//epoch_1.jpg >>>\n",
      "[01/10/2019 19:10:14] <<< Saving model to trained_models/gkb_model//epoch_1 ... >>>\n",
      "[01/10/2019 19:10:14] <<< Saving model_init to trained_models/gkb_model//epoch_1_structure_init.json... >>>\n",
      "[01/10/2019 19:10:14] <<< Saving model_next to trained_models/gkb_model//epoch_1_structure_next.json... >>>\n",
      "[01/10/2019 19:10:14] <<< Model saved >>>\n",
      "[01/10/2019 19:10:14] <<< Saving model to trained_models/gkb_model//epoch_1 ... >>>\n",
      "[01/10/2019 19:10:15] <<< Saving model_init to trained_models/gkb_model//epoch_1_structure_init.json... >>>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[01/10/2019 19:10:15] <<< Saving model_next to trained_models/gkb_model//epoch_1_structure_next.json... >>>\n",
      "[01/10/2019 19:10:17] <<< Model saved >>>\n",
      "[01/10/2019 19:23:30] WARNING: parallel loaders are not implemented\n",
      "[01/10/2019 19:23:30] <<< Predicting outputs of val set >>>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sampling 200/200  -  ETA: 2s   \n",
      " Total cost of the translations: 2096.534185 \t Average cost of the translations: 10.482671\n",
      "The sampling took: 552.624177 secs (Speed: 2.763121 sec/sample)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[01/10/2019 19:32:43] Prediction output 0: target_text (text)\n",
      "[01/10/2019 19:32:43] Decoding beam search prediction ...\n",
      "[01/10/2019 19:32:43] Evaluating on metric coco\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[01/10/2019 19:32:53] Computing coco scores on the val split...\n",
      "[01/10/2019 19:32:53] Bleu_1: 0.493831637364\n",
      "[01/10/2019 19:32:53] Bleu_2: 0.300947104371\n",
      "[01/10/2019 19:32:53] Bleu_3: 0.195007746279\n",
      "[01/10/2019 19:32:53] Bleu_4: 0.135607180681\n",
      "[01/10/2019 19:32:53] CIDEr: 0.954492888634\n",
      "[01/10/2019 19:32:53] METEOR: 0.327565939833\n",
      "[01/10/2019 19:32:53] ROUGE_L: 0.47215110653\n",
      "[01/10/2019 19:32:53] TER: 0.670848267622\n",
      "[01/10/2019 19:32:53] Done evaluating on metric coco\n",
      "[01/10/2019 19:32:53] <<< Progress plot saved in trained_models/gkb_model//epoch_2.jpg >>>\n",
      "[01/10/2019 19:32:53] <<< Saving model to trained_models/gkb_model//epoch_2 ... >>>\n",
      "[01/10/2019 19:32:54] <<< Saving model_init to trained_models/gkb_model//epoch_2_structure_init.json... >>>\n",
      "[01/10/2019 19:32:54] <<< Saving model_next to trained_models/gkb_model//epoch_2_structure_next.json... >>>\n",
      "[01/10/2019 19:32:54] <<< Model saved >>>\n",
      "[01/10/2019 19:32:54] <<< Saving model to trained_models/gkb_model//epoch_2 ... >>>\n",
      "[01/10/2019 19:32:54] <<< Saving model_init to trained_models/gkb_model//epoch_2_structure_init.json... >>>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[01/10/2019 19:32:55] <<< Saving model_next to trained_models/gkb_model//epoch_2_structure_next.json... >>>\n",
      "[01/10/2019 19:32:55] <<< Model saved >>>\n",
      "[01/10/2019 19:46:09] WARNING: parallel loaders are not implemented\n",
      "[01/10/2019 19:46:09] <<< Predicting outputs of val set >>>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sampling 200/200  -  ETA: 2s   \n",
      " Total cost of the translations: 1993.566623 \t Average cost of the translations: 9.967833\n",
      "The sampling took: 579.134264 secs (Speed: 2.895671 sec/sample)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[01/10/2019 19:55:48] Prediction output 0: target_text (text)\n",
      "[01/10/2019 19:55:48] Decoding beam search prediction ...\n",
      "[01/10/2019 19:55:48] Evaluating on metric coco\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[01/10/2019 19:55:58] Computing coco scores on the val split...\n",
      "[01/10/2019 19:55:58] Bleu_1: 0.562862753193\n",
      "[01/10/2019 19:55:58] Bleu_2: 0.366940752407\n",
      "[01/10/2019 19:55:58] Bleu_3: 0.256257085687\n",
      "[01/10/2019 19:55:58] Bleu_4: 0.188644861688\n",
      "[01/10/2019 19:55:58] CIDEr: 1.57332697277\n",
      "[01/10/2019 19:55:58] METEOR: 0.359019091846\n",
      "[01/10/2019 19:55:58] ROUGE_L: 0.507315032247\n",
      "[01/10/2019 19:55:58] TER: 0.628434886499\n",
      "[01/10/2019 19:55:58] Done evaluating on metric coco\n",
      "[01/10/2019 19:55:58] <<< Progress plot saved in trained_models/gkb_model//epoch_3.jpg >>>\n",
      "[01/10/2019 19:55:58] <<< Saving model to trained_models/gkb_model//epoch_3 ... >>>\n",
      "[01/10/2019 19:55:58] <<< Saving model_init to trained_models/gkb_model//epoch_3_structure_init.json... >>>\n",
      "[01/10/2019 19:55:59] <<< Saving model_next to trained_models/gkb_model//epoch_3_structure_next.json... >>>\n",
      "[01/10/2019 19:55:59] <<< Model saved >>>\n",
      "[01/10/2019 19:55:59] <<< Saving model to trained_models/gkb_model//epoch_3 ... >>>\n",
      "[01/10/2019 19:55:59] <<< Saving model_init to trained_models/gkb_model//epoch_3_structure_init.json... >>>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[01/10/2019 19:56:00] <<< Saving model_next to trained_models/gkb_model//epoch_3_structure_next.json... >>>\n",
      "[01/10/2019 19:56:00] <<< Model saved >>>\n",
      "[01/10/2019 20:09:14] WARNING: parallel loaders are not implemented\n",
      "[01/10/2019 20:09:14] <<< Predicting outputs of val set >>>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sampling 200/200  -  ETA: 2s   \n",
      " Total cost of the translations: 1710.692736 \t Average cost of the translations: 8.553464\n",
      "The sampling took: 568.665415 secs (Speed: 2.843327 sec/sample)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[01/10/2019 20:18:43] Prediction output 0: target_text (text)\n",
      "[01/10/2019 20:18:43] Decoding beam search prediction ...\n",
      "[01/10/2019 20:18:43] Evaluating on metric coco\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[01/10/2019 20:18:53] Computing coco scores on the val split...\n",
      "[01/10/2019 20:18:53] Bleu_1: 0.565538611817\n",
      "[01/10/2019 20:18:53] Bleu_2: 0.375760010543\n",
      "[01/10/2019 20:18:53] Bleu_3: 0.264113605996\n",
      "[01/10/2019 20:18:53] Bleu_4: 0.192996875083\n",
      "[01/10/2019 20:18:53] CIDEr: 1.61939608618\n",
      "[01/10/2019 20:18:53] METEOR: 0.359952703553\n",
      "[01/10/2019 20:18:53] ROUGE_L: 0.517273054734\n",
      "[01/10/2019 20:18:53] TER: 0.629032258065\n",
      "[01/10/2019 20:18:53] Done evaluating on metric coco\n",
      "[01/10/2019 20:18:53] <<< Progress plot saved in trained_models/gkb_model//epoch_4.jpg >>>\n",
      "[01/10/2019 20:18:53] <<< Saving model to trained_models/gkb_model//epoch_4 ... >>>\n",
      "[01/10/2019 20:18:53] <<< Saving model_init to trained_models/gkb_model//epoch_4_structure_init.json... >>>\n",
      "[01/10/2019 20:18:53] <<< Saving model_next to trained_models/gkb_model//epoch_4_structure_next.json... >>>\n",
      "[01/10/2019 20:18:53] <<< Model saved >>>\n",
      "[01/10/2019 20:18:53] <<< Saving model to trained_models/gkb_model//epoch_4 ... >>>\n",
      "[01/10/2019 20:18:54] <<< Saving model_init to trained_models/gkb_model//epoch_4_structure_init.json... >>>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[01/10/2019 20:18:54] <<< Saving model_next to trained_models/gkb_model//epoch_4_structure_next.json... >>>\n",
      "[01/10/2019 20:18:55] <<< Model saved >>>\n",
      "[01/10/2019 20:32:09] WARNING: parallel loaders are not implemented\n",
      "[01/10/2019 20:32:09] <<< Predicting outputs of val set >>>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sampling 200/200  -  ETA: 2s   \n",
      " Total cost of the translations: 1655.412314 \t Average cost of the translations: 8.277062\n",
      "The sampling took: 574.699996 secs (Speed: 2.873500 sec/sample)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[01/10/2019 20:41:43] Prediction output 0: target_text (text)\n",
      "[01/10/2019 20:41:43] Decoding beam search prediction ...\n",
      "[01/10/2019 20:41:43] Evaluating on metric coco\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[01/10/2019 20:41:54] Computing coco scores on the val split...\n",
      "[01/10/2019 20:41:54] Bleu_1: 0.587985019077\n",
      "[01/10/2019 20:41:54] Bleu_2: 0.406449002875\n",
      "[01/10/2019 20:41:54] Bleu_3: 0.296076724654\n",
      "[01/10/2019 20:41:54] Bleu_4: 0.222502758494\n",
      "[01/10/2019 20:41:54] CIDEr: 1.86801329074\n",
      "[01/10/2019 20:41:54] METEOR: 0.372370723864\n",
      "[01/10/2019 20:41:54] ROUGE_L: 0.542721504177\n",
      "[01/10/2019 20:41:54] TER: 0.609318996416\n",
      "[01/10/2019 20:41:54] Done evaluating on metric coco\n",
      "[01/10/2019 20:41:54] <<< Progress plot saved in trained_models/gkb_model//epoch_5.jpg >>>\n",
      "[01/10/2019 20:41:54] <<< Saving model to trained_models/gkb_model//epoch_5 ... >>>\n",
      "[01/10/2019 20:41:54] <<< Saving model_init to trained_models/gkb_model//epoch_5_structure_init.json... >>>\n",
      "[01/10/2019 20:41:54] <<< Saving model_next to trained_models/gkb_model//epoch_5_structure_next.json... >>>\n",
      "[01/10/2019 20:41:54] <<< Model saved >>>\n",
      "[01/10/2019 20:41:54] <<< Saving model to trained_models/gkb_model//epoch_5 ... >>>\n",
      "[01/10/2019 20:41:55] <<< Saving model_init to trained_models/gkb_model//epoch_5_structure_init.json... >>>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[01/10/2019 20:41:55] <<< Saving model_next to trained_models/gkb_model//epoch_5_structure_next.json... >>>\n",
      "[01/10/2019 20:41:56] <<< Model saved >>>\n",
      "[01/10/2019 20:55:09] WARNING: parallel loaders are not implemented\n",
      "[01/10/2019 20:55:09] <<< Predicting outputs of val set >>>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sampling 200/200  -  ETA: 2s   \n",
      " Total cost of the translations: 1511.254027 \t Average cost of the translations: 7.556270\n",
      "The sampling took: 582.470210 secs (Speed: 2.912351 sec/sample)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[01/10/2019 21:04:52] Prediction output 0: target_text (text)\n",
      "[01/10/2019 21:04:52] Decoding beam search prediction ...\n",
      "[01/10/2019 21:04:52] Evaluating on metric coco\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[01/10/2019 21:05:02] Computing coco scores on the val split...\n",
      "[01/10/2019 21:05:02] Bleu_1: 0.61600790395\n",
      "[01/10/2019 21:05:02] Bleu_2: 0.438216956239\n",
      "[01/10/2019 21:05:02] Bleu_3: 0.328477338962\n",
      "[01/10/2019 21:05:02] Bleu_4: 0.252835589402\n",
      "[01/10/2019 21:05:02] CIDEr: 2.01124340086\n",
      "[01/10/2019 21:05:02] METEOR: 0.386160731184\n",
      "[01/10/2019 21:05:02] ROUGE_L: 0.55605880921\n",
      "[01/10/2019 21:05:02] TER: 0.576164874552\n",
      "[01/10/2019 21:05:02] Done evaluating on metric coco\n",
      "[01/10/2019 21:05:02] <<< Progress plot saved in trained_models/gkb_model//epoch_6.jpg >>>\n",
      "[01/10/2019 21:05:02] <<< Saving model to trained_models/gkb_model//epoch_6 ... >>>\n",
      "[01/10/2019 21:05:02] <<< Saving model_init to trained_models/gkb_model//epoch_6_structure_init.json... >>>\n",
      "[01/10/2019 21:05:02] <<< Saving model_next to trained_models/gkb_model//epoch_6_structure_next.json... >>>\n",
      "[01/10/2019 21:05:02] <<< Model saved >>>\n",
      "[01/10/2019 21:05:02] <<< Saving model to trained_models/gkb_model//epoch_6 ... >>>\n",
      "[01/10/2019 21:05:03] <<< Saving model_init to trained_models/gkb_model//epoch_6_structure_init.json... >>>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[01/10/2019 21:05:03] <<< Saving model_next to trained_models/gkb_model//epoch_6_structure_next.json... >>>\n",
      "[01/10/2019 21:05:04] <<< Model saved >>>\n",
      "[01/10/2019 21:18:17] WARNING: parallel loaders are not implemented\n",
      "[01/10/2019 21:18:17] <<< Predicting outputs of val set >>>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sampling 200/200  -  ETA: 2s   \n",
      " Total cost of the translations: 1379.449386 \t Average cost of the translations: 6.897247\n",
      "The sampling took: 573.665098 secs (Speed: 2.868325 sec/sample)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[01/10/2019 21:27:51] Prediction output 0: target_text (text)\n",
      "[01/10/2019 21:27:51] Decoding beam search prediction ...\n",
      "[01/10/2019 21:27:51] Evaluating on metric coco\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[01/10/2019 21:28:01] Computing coco scores on the val split...\n",
      "[01/10/2019 21:28:01] Bleu_1: 0.619639298823\n",
      "[01/10/2019 21:28:01] Bleu_2: 0.448614792867\n",
      "[01/10/2019 21:28:01] Bleu_3: 0.341902144705\n",
      "[01/10/2019 21:28:01] Bleu_4: 0.266800692199\n",
      "[01/10/2019 21:28:01] CIDEr: 2.2469214889\n",
      "[01/10/2019 21:28:01] METEOR: 0.392324878188\n",
      "[01/10/2019 21:28:01] ROUGE_L: 0.573016387864\n",
      "[01/10/2019 21:28:01] TER: 0.570191158901\n",
      "[01/10/2019 21:28:01] Done evaluating on metric coco\n",
      "[01/10/2019 21:28:01] <<< Progress plot saved in trained_models/gkb_model//epoch_7.jpg >>>\n",
      "[01/10/2019 21:28:01] <<< Saving model to trained_models/gkb_model//epoch_7 ... >>>\n",
      "[01/10/2019 21:28:02] <<< Saving model_init to trained_models/gkb_model//epoch_7_structure_init.json... >>>\n",
      "[01/10/2019 21:28:02] <<< Saving model_next to trained_models/gkb_model//epoch_7_structure_next.json... >>>\n",
      "[01/10/2019 21:28:02] <<< Model saved >>>\n",
      "[01/10/2019 21:28:02] <<< Saving model to trained_models/gkb_model//epoch_7 ... >>>\n",
      "[01/10/2019 21:28:02] <<< Saving model_init to trained_models/gkb_model//epoch_7_structure_init.json... >>>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[01/10/2019 21:28:03] <<< Saving model_next to trained_models/gkb_model//epoch_7_structure_next.json... >>>\n",
      "[01/10/2019 21:28:03] <<< Model saved >>>\n",
      "[01/10/2019 21:41:17] WARNING: parallel loaders are not implemented\n",
      "[01/10/2019 21:41:17] <<< Predicting outputs of val set >>>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sampling 200/200  -  ETA: 2s   \n",
      " Total cost of the translations: 1255.857120 \t Average cost of the translations: 6.279286\n",
      "The sampling took: 572.599788 secs (Speed: 2.862999 sec/sample)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[01/10/2019 21:50:50] Prediction output 0: target_text (text)\n",
      "[01/10/2019 21:50:50] Decoding beam search prediction ...\n",
      "[01/10/2019 21:50:50] Evaluating on metric coco\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[01/10/2019 21:51:00] Computing coco scores on the val split...\n",
      "[01/10/2019 21:51:00] Bleu_1: 0.624792194878\n",
      "[01/10/2019 21:51:00] Bleu_2: 0.457806304275\n",
      "[01/10/2019 21:51:00] Bleu_3: 0.35151590343\n",
      "[01/10/2019 21:51:00] Bleu_4: 0.279042724143\n",
      "[01/10/2019 21:51:00] CIDEr: 2.41003263009\n",
      "[01/10/2019 21:51:00] METEOR: 0.392145396862\n",
      "[01/10/2019 21:51:00] ROUGE_L: 0.580320228901\n",
      "[01/10/2019 21:51:00] TER: 0.544802867384\n",
      "[01/10/2019 21:51:00] Done evaluating on metric coco\n",
      "[01/10/2019 21:51:00] <<< Progress plot saved in trained_models/gkb_model//epoch_8.jpg >>>\n",
      "[01/10/2019 21:51:00] <<< Saving model to trained_models/gkb_model//epoch_8 ... >>>\n",
      "[01/10/2019 21:51:00] <<< Saving model_init to trained_models/gkb_model//epoch_8_structure_init.json... >>>\n",
      "[01/10/2019 21:51:00] <<< Saving model_next to trained_models/gkb_model//epoch_8_structure_next.json... >>>\n",
      "[01/10/2019 21:51:00] <<< Model saved >>>\n",
      "[01/10/2019 21:51:00] <<< Saving model to trained_models/gkb_model//epoch_8 ... >>>\n",
      "[01/10/2019 21:51:01] <<< Saving model_init to trained_models/gkb_model//epoch_8_structure_init.json... >>>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[01/10/2019 21:51:01] <<< Saving model_next to trained_models/gkb_model//epoch_8_structure_next.json... >>>\n",
      "[01/10/2019 21:51:02] <<< Model saved >>>\n",
      "[01/10/2019 22:04:15] WARNING: parallel loaders are not implemented\n",
      "[01/10/2019 22:04:15] <<< Predicting outputs of val set >>>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sampling 200/200  -  ETA: 2s   \n",
      " Total cost of the translations: 1219.257165 \t Average cost of the translations: 6.096286\n",
      "The sampling took: 584.030514 secs (Speed: 2.920153 sec/sample)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[01/10/2019 22:13:59] Prediction output 0: target_text (text)\n",
      "[01/10/2019 22:13:59] Decoding beam search prediction ...\n",
      "[01/10/2019 22:13:59] Evaluating on metric coco\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[01/10/2019 22:14:09] Computing coco scores on the val split...\n",
      "[01/10/2019 22:14:09] Bleu_1: 0.628276204087\n",
      "[01/10/2019 22:14:09] Bleu_2: 0.461147712666\n",
      "[01/10/2019 22:14:09] Bleu_3: 0.351412150545\n",
      "[01/10/2019 22:14:09] Bleu_4: 0.27489618476\n",
      "[01/10/2019 22:14:09] CIDEr: 2.34079736883\n",
      "[01/10/2019 22:14:09] METEOR: 0.398641983306\n",
      "[01/10/2019 22:14:09] ROUGE_L: 0.579681850456\n",
      "[01/10/2019 22:14:09] TER: 0.553464755078\n",
      "[01/10/2019 22:14:09] Done evaluating on metric coco\n",
      "[01/10/2019 22:14:10] <<< Progress plot saved in trained_models/gkb_model//epoch_9.jpg >>>\n",
      "[01/10/2019 22:14:10] <<< Saving model to trained_models/gkb_model//epoch_9 ... >>>\n",
      "[01/10/2019 22:14:10] <<< Saving model_init to trained_models/gkb_model//epoch_9_structure_init.json... >>>\n",
      "[01/10/2019 22:14:10] <<< Saving model_next to trained_models/gkb_model//epoch_9_structure_next.json... >>>\n",
      "[01/10/2019 22:14:10] <<< Model saved >>>\n",
      "[01/10/2019 22:14:10] <<< Saving model to trained_models/gkb_model//epoch_9 ... >>>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[01/10/2019 22:14:10] <<< Saving model_init to trained_models/gkb_model//epoch_9_structure_init.json... >>>\n",
      "[01/10/2019 22:14:11] <<< Saving model_next to trained_models/gkb_model//epoch_9_structure_next.json... >>>\n",
      "[01/10/2019 22:14:12] <<< Model saved >>>\n",
      "[01/10/2019 22:27:25] WARNING: parallel loaders are not implemented\n",
      "[01/10/2019 22:27:25] <<< Predicting outputs of val set >>>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sampling 200/200  -  ETA: 2s   \n",
      " Total cost of the translations: 1131.863054 \t Average cost of the translations: 5.659315\n",
      "The sampling took: 560.980073 secs (Speed: 2.804900 sec/sample)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[01/10/2019 22:36:46] Prediction output 0: target_text (text)\n",
      "[01/10/2019 22:36:46] Decoding beam search prediction ...\n",
      "[01/10/2019 22:36:46] Evaluating on metric coco\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[01/10/2019 22:36:56] Computing coco scores on the val split...\n",
      "[01/10/2019 22:36:56] Bleu_1: 0.628554104163\n",
      "[01/10/2019 22:36:56] Bleu_2: 0.46302281029\n",
      "[01/10/2019 22:36:56] Bleu_3: 0.357103168001\n",
      "[01/10/2019 22:36:56] Bleu_4: 0.282595893251\n",
      "[01/10/2019 22:36:56] CIDEr: 2.42785576783\n",
      "[01/10/2019 22:36:56] METEOR: 0.400281862331\n",
      "[01/10/2019 22:36:56] ROUGE_L: 0.576715220117\n",
      "[01/10/2019 22:36:56] TER: 0.53853046595\n",
      "[01/10/2019 22:36:56] Done evaluating on metric coco\n",
      "[01/10/2019 22:36:56] <<< Progress plot saved in trained_models/gkb_model//epoch_10.jpg >>>\n",
      "[01/10/2019 22:36:56] <<< Saving model to trained_models/gkb_model//epoch_10 ... >>>\n",
      "[01/10/2019 22:36:56] <<< Saving model_init to trained_models/gkb_model//epoch_10_structure_init.json... >>>\n",
      "[01/10/2019 22:36:56] <<< Saving model_next to trained_models/gkb_model//epoch_10_structure_next.json... >>>\n",
      "[01/10/2019 22:36:56] <<< Model saved >>>\n",
      "[01/10/2019 22:36:56] <<< Saving model to trained_models/gkb_model//epoch_10 ... >>>\n",
      "[01/10/2019 22:36:57] <<< Saving model_init to trained_models/gkb_model//epoch_10_structure_init.json... >>>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[01/10/2019 22:36:57] <<< Saving model_next to trained_models/gkb_model//epoch_10_structure_next.json... >>>\n",
      "[01/10/2019 22:36:58] <<< Model saved >>>\n",
      "[01/10/2019 22:50:11] WARNING: parallel loaders are not implemented\n",
      "[01/10/2019 22:50:11] <<< Predicting outputs of val set >>>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sampling 200/200  -  ETA: 2s   \n",
      " Total cost of the translations: 1120.657632 \t Average cost of the translations: 5.603288\n",
      "The sampling took: 588.232336 secs (Speed: 2.941162 sec/sample)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[01/10/2019 22:59:59] Prediction output 0: target_text (text)\n",
      "[01/10/2019 22:59:59] Decoding beam search prediction ...\n",
      "[01/10/2019 22:59:59] Evaluating on metric coco\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[01/10/2019 23:00:09] Computing coco scores on the val split...\n",
      "[01/10/2019 23:00:09] Bleu_1: 0.653697660761\n",
      "[01/10/2019 23:00:09] Bleu_2: 0.485106382049\n",
      "[01/10/2019 23:00:09] Bleu_3: 0.376851047372\n",
      "[01/10/2019 23:00:09] Bleu_4: 0.302600832812\n",
      "[01/10/2019 23:00:09] CIDEr: 2.5330141349\n",
      "[01/10/2019 23:00:09] METEOR: 0.41115157966\n",
      "[01/10/2019 23:00:09] ROUGE_L: 0.587555770363\n",
      "[01/10/2019 23:00:09] TER: 0.536439665472\n",
      "[01/10/2019 23:00:09] Done evaluating on metric coco\n",
      "[01/10/2019 23:00:10] <<< Progress plot saved in trained_models/gkb_model//epoch_11.jpg >>>\n",
      "[01/10/2019 23:00:10] <<< Saving model to trained_models/gkb_model//epoch_11 ... >>>\n",
      "[01/10/2019 23:00:10] <<< Saving model_init to trained_models/gkb_model//epoch_11_structure_init.json... >>>\n",
      "[01/10/2019 23:00:10] <<< Saving model_next to trained_models/gkb_model//epoch_11_structure_next.json... >>>\n",
      "[01/10/2019 23:00:10] <<< Model saved >>>\n",
      "[01/10/2019 23:00:10] <<< Saving model to trained_models/gkb_model//epoch_11 ... >>>\n",
      "[01/10/2019 23:00:10] <<< Saving model_init to trained_models/gkb_model//epoch_11_structure_init.json... >>>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[01/10/2019 23:00:11] <<< Saving model_next to trained_models/gkb_model//epoch_11_structure_next.json... >>>\n",
      "[01/10/2019 23:00:12] <<< Model saved >>>\n",
      "[01/10/2019 23:13:25] WARNING: parallel loaders are not implemented\n",
      "[01/10/2019 23:13:25] <<< Predicting outputs of val set >>>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sampling 200/200  -  ETA: 2s   \n",
      " Total cost of the translations: 1048.271796 \t Average cost of the translations: 5.241359\n",
      "The sampling took: 581.261868 secs (Speed: 2.906309 sec/sample)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[01/10/2019 23:23:06] Prediction output 0: target_text (text)\n",
      "[01/10/2019 23:23:06] Decoding beam search prediction ...\n",
      "[01/10/2019 23:23:06] Evaluating on metric coco\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[01/10/2019 23:23:16] Computing coco scores on the val split...\n",
      "[01/10/2019 23:23:16] Bleu_1: 0.643762435844\n",
      "[01/10/2019 23:23:16] Bleu_2: 0.481948577851\n",
      "[01/10/2019 23:23:16] Bleu_3: 0.377390138539\n",
      "[01/10/2019 23:23:16] Bleu_4: 0.30311490368\n",
      "[01/10/2019 23:23:16] CIDEr: 2.58989938997\n",
      "[01/10/2019 23:23:16] METEOR: 0.408904169296\n",
      "[01/10/2019 23:23:16] ROUGE_L: 0.589046495278\n",
      "[01/10/2019 23:23:16] TER: 0.532556750299\n",
      "[01/10/2019 23:23:16] Done evaluating on metric coco\n",
      "[01/10/2019 23:23:16] <<< Progress plot saved in trained_models/gkb_model//epoch_12.jpg >>>\n",
      "[01/10/2019 23:23:16] <<< Saving model to trained_models/gkb_model//epoch_12 ... >>>\n",
      "[01/10/2019 23:23:17] <<< Saving model_init to trained_models/gkb_model//epoch_12_structure_init.json... >>>\n",
      "[01/10/2019 23:23:17] <<< Saving model_next to trained_models/gkb_model//epoch_12_structure_next.json... >>>\n",
      "[01/10/2019 23:23:17] <<< Model saved >>>\n",
      "[01/10/2019 23:23:17] <<< Saving model to trained_models/gkb_model//epoch_12 ... >>>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[01/10/2019 23:23:17] <<< Saving model_init to trained_models/gkb_model//epoch_12_structure_init.json... >>>\n",
      "[01/10/2019 23:23:18] <<< Saving model_next to trained_models/gkb_model//epoch_12_structure_next.json... >>>\n",
      "[01/10/2019 23:23:18] <<< Model saved >>>\n",
      "[01/10/2019 23:36:32] WARNING: parallel loaders are not implemented\n",
      "[01/10/2019 23:36:32] <<< Predicting outputs of val set >>>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sampling 200/200  -  ETA: 2s   \n",
      " Total cost of the translations: 996.782362 \t Average cost of the translations: 4.983912\n",
      "The sampling took: 577.187501 secs (Speed: 2.885938 sec/sample)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[01/10/2019 23:46:09] Prediction output 0: target_text (text)\n",
      "[01/10/2019 23:46:09] Decoding beam search prediction ...\n",
      "[01/10/2019 23:46:09] Evaluating on metric coco\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[01/10/2019 23:46:19] Computing coco scores on the val split...\n",
      "[01/10/2019 23:46:19] Bleu_1: 0.649662534365\n",
      "[01/10/2019 23:46:19] Bleu_2: 0.490719788139\n",
      "[01/10/2019 23:46:19] Bleu_3: 0.384392239814\n",
      "[01/10/2019 23:46:19] Bleu_4: 0.31054153306\n",
      "[01/10/2019 23:46:19] CIDEr: 2.75432417671\n",
      "[01/10/2019 23:46:19] METEOR: 0.409884300013\n",
      "[01/10/2019 23:46:19] ROUGE_L: 0.594499398202\n",
      "[01/10/2019 23:46:19] TER: 0.525388291517\n",
      "[01/10/2019 23:46:19] Done evaluating on metric coco\n",
      "[01/10/2019 23:46:19] <<< Progress plot saved in trained_models/gkb_model//epoch_13.jpg >>>\n",
      "[01/10/2019 23:46:19] <<< Saving model to trained_models/gkb_model//epoch_13 ... >>>\n",
      "[01/10/2019 23:46:19] <<< Saving model_init to trained_models/gkb_model//epoch_13_structure_init.json... >>>\n",
      "[01/10/2019 23:46:20] <<< Saving model_next to trained_models/gkb_model//epoch_13_structure_next.json... >>>\n",
      "[01/10/2019 23:46:20] <<< Model saved >>>\n",
      "[01/10/2019 23:46:20] <<< Saving model to trained_models/gkb_model//epoch_13 ... >>>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[01/10/2019 23:46:20] <<< Saving model_init to trained_models/gkb_model//epoch_13_structure_init.json... >>>\n",
      "[01/10/2019 23:46:21] <<< Saving model_next to trained_models/gkb_model//epoch_13_structure_next.json... >>>\n",
      "[01/10/2019 23:46:21] <<< Model saved >>>\n",
      "[01/10/2019 23:59:35] WARNING: parallel loaders are not implemented\n",
      "[01/10/2019 23:59:35] <<< Predicting outputs of val set >>>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sampling 200/200  -  ETA: 2s   \n",
      " Total cost of the translations: 964.946227 \t Average cost of the translations: 4.824731\n",
      "The sampling took: 577.980706 secs (Speed: 2.889904 sec/sample)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[02/10/2019 00:09:13] Prediction output 0: target_text (text)\n",
      "[02/10/2019 00:09:13] Decoding beam search prediction ...\n",
      "[02/10/2019 00:09:13] Evaluating on metric coco\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[02/10/2019 00:09:23] Computing coco scores on the val split...\n",
      "[02/10/2019 00:09:23] Bleu_1: 0.643720615919\n",
      "[02/10/2019 00:09:23] Bleu_2: 0.478121258481\n",
      "[02/10/2019 00:09:23] Bleu_3: 0.372942643803\n",
      "[02/10/2019 00:09:23] Bleu_4: 0.298781927573\n",
      "[02/10/2019 00:09:23] CIDEr: 2.46735018466\n",
      "[02/10/2019 00:09:23] METEOR: 0.409307662529\n",
      "[02/10/2019 00:09:23] ROUGE_L: 0.582217606558\n",
      "[02/10/2019 00:09:23] TER: 0.545400238949\n",
      "[02/10/2019 00:09:23] Done evaluating on metric coco\n",
      "[02/10/2019 00:09:23] <<< Progress plot saved in trained_models/gkb_model//epoch_14.jpg >>>\n",
      "[02/10/2019 00:09:23] <<< Saving model to trained_models/gkb_model//epoch_14 ... >>>\n",
      "[02/10/2019 00:09:24] <<< Saving model_init to trained_models/gkb_model//epoch_14_structure_init.json... >>>\n",
      "[02/10/2019 00:09:24] <<< Saving model_next to trained_models/gkb_model//epoch_14_structure_next.json... >>>\n",
      "[02/10/2019 00:09:24] <<< Model saved >>>\n",
      "[02/10/2019 00:09:24] <<< Saving model to trained_models/gkb_model//epoch_14 ... >>>\n",
      "[02/10/2019 00:09:24] <<< Saving model_init to trained_models/gkb_model//epoch_14_structure_init.json... >>>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[02/10/2019 00:09:25] <<< Saving model_next to trained_models/gkb_model//epoch_14_structure_next.json... >>>\n",
      "[02/10/2019 00:09:25] <<< Model saved >>>\n",
      "[02/10/2019 00:22:38] WARNING: parallel loaders are not implemented\n",
      "[02/10/2019 00:22:38] <<< Predicting outputs of val set >>>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sampling 200/200  -  ETA: 2s   \n",
      " Total cost of the translations: 904.992015 \t Average cost of the translations: 4.524960\n",
      "The sampling took: 573.874317 secs (Speed: 2.869372 sec/sample)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[02/10/2019 00:32:12] Prediction output 0: target_text (text)\n",
      "[02/10/2019 00:32:12] Decoding beam search prediction ...\n",
      "[02/10/2019 00:32:12] Evaluating on metric coco\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[02/10/2019 00:32:22] Computing coco scores on the val split...\n",
      "[02/10/2019 00:32:22] Bleu_1: 0.640489029524\n",
      "[02/10/2019 00:32:22] Bleu_2: 0.482366909555\n",
      "[02/10/2019 00:32:22] Bleu_3: 0.378836805263\n",
      "[02/10/2019 00:32:22] Bleu_4: 0.303510248761\n",
      "[02/10/2019 00:32:22] CIDEr: 2.50378623267\n",
      "[02/10/2019 00:32:22] METEOR: 0.410120570472\n",
      "[02/10/2019 00:32:22] ROUGE_L: 0.585266645935\n",
      "[02/10/2019 00:32:22] TER: 0.522998805257\n",
      "[02/10/2019 00:32:22] Done evaluating on metric coco\n",
      "[02/10/2019 00:32:22] <<< Progress plot saved in trained_models/gkb_model//epoch_15.jpg >>>\n",
      "[02/10/2019 00:32:22] <<< Saving model to trained_models/gkb_model//epoch_15 ... >>>\n",
      "[02/10/2019 00:32:23] <<< Saving model_init to trained_models/gkb_model//epoch_15_structure_init.json... >>>\n",
      "[02/10/2019 00:32:23] <<< Saving model_next to trained_models/gkb_model//epoch_15_structure_next.json... >>>\n",
      "[02/10/2019 00:32:23] <<< Model saved >>>\n",
      "[02/10/2019 00:32:23] <<< Saving model to trained_models/gkb_model//epoch_15 ... >>>\n",
      "[02/10/2019 00:32:23] <<< Saving model_init to trained_models/gkb_model//epoch_15_structure_init.json... >>>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[02/10/2019 00:32:23] <<< Saving model_next to trained_models/gkb_model//epoch_15_structure_next.json... >>>\n",
      "[02/10/2019 00:32:24] <<< Model saved >>>\n",
      "[02/10/2019 00:45:37] WARNING: parallel loaders are not implemented\n",
      "[02/10/2019 00:45:37] <<< Predicting outputs of val set >>>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sampling 200/200  -  ETA: 2s   \n",
      " Total cost of the translations: 899.808892 \t Average cost of the translations: 4.499044\n",
      "The sampling took: 591.170445 secs (Speed: 2.955852 sec/sample)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[02/10/2019 00:55:29] Prediction output 0: target_text (text)\n",
      "[02/10/2019 00:55:29] Decoding beam search prediction ...\n",
      "[02/10/2019 00:55:29] Evaluating on metric coco\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[02/10/2019 00:55:39] Computing coco scores on the val split...\n",
      "[02/10/2019 00:55:39] Bleu_1: 0.667881326686\n",
      "[02/10/2019 00:55:39] Bleu_2: 0.507144588738\n",
      "[02/10/2019 00:55:39] Bleu_3: 0.401768003569\n",
      "[02/10/2019 00:55:39] Bleu_4: 0.328252739426\n",
      "[02/10/2019 00:55:39] CIDEr: 2.8646150291\n",
      "[02/10/2019 00:55:39] METEOR: 0.418128667864\n",
      "[02/10/2019 00:55:39] ROUGE_L: 0.599992622322\n",
      "[02/10/2019 00:55:39] TER: 0.512544802867\n",
      "[02/10/2019 00:55:39] Done evaluating on metric coco\n",
      "[02/10/2019 00:55:39] <<< Progress plot saved in trained_models/gkb_model//epoch_16.jpg >>>\n",
      "[02/10/2019 00:55:39] <<< Saving model to trained_models/gkb_model//epoch_16 ... >>>\n",
      "[02/10/2019 00:55:39] <<< Saving model_init to trained_models/gkb_model//epoch_16_structure_init.json... >>>\n",
      "[02/10/2019 00:55:39] <<< Saving model_next to trained_models/gkb_model//epoch_16_structure_next.json... >>>\n",
      "[02/10/2019 00:55:39] <<< Model saved >>>\n",
      "[02/10/2019 00:55:39] <<< Saving model to trained_models/gkb_model//epoch_16 ... >>>\n",
      "[02/10/2019 00:55:40] <<< Saving model_init to trained_models/gkb_model//epoch_16_structure_init.json... >>>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[02/10/2019 00:55:40] <<< Saving model_next to trained_models/gkb_model//epoch_16_structure_next.json... >>>\n",
      "[02/10/2019 00:55:40] <<< Model saved >>>\n",
      "[02/10/2019 01:08:54] WARNING: parallel loaders are not implemented\n",
      "[02/10/2019 01:08:54] <<< Predicting outputs of val set >>>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sampling 200/200  -  ETA: 2s   \n",
      " Total cost of the translations: 864.449681 \t Average cost of the translations: 4.322248\n",
      "The sampling took: 587.841310 secs (Speed: 2.939207 sec/sample)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[02/10/2019 01:18:42] Prediction output 0: target_text (text)\n",
      "[02/10/2019 01:18:42] Decoding beam search prediction ...\n",
      "[02/10/2019 01:18:42] Evaluating on metric coco\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[02/10/2019 01:18:52] Computing coco scores on the val split...\n",
      "[02/10/2019 01:18:52] Bleu_1: 0.656174138192\n",
      "[02/10/2019 01:18:52] Bleu_2: 0.49600514633\n",
      "[02/10/2019 01:18:52] Bleu_3: 0.394580229434\n",
      "[02/10/2019 01:18:52] Bleu_4: 0.322621003067\n",
      "[02/10/2019 01:18:52] CIDEr: 2.70406139107\n",
      "[02/10/2019 01:18:52] METEOR: 0.415993515633\n",
      "[02/10/2019 01:18:52] ROUGE_L: 0.586253132367\n",
      "[02/10/2019 01:18:52] TER: 0.530167264038\n",
      "[02/10/2019 01:18:52] Done evaluating on metric coco\n",
      "[02/10/2019 01:18:52] <<< Progress plot saved in trained_models/gkb_model//epoch_17.jpg >>>\n",
      "[02/10/2019 01:18:52] <<< Saving model to trained_models/gkb_model//epoch_17 ... >>>\n",
      "[02/10/2019 01:18:52] <<< Saving model_init to trained_models/gkb_model//epoch_17_structure_init.json... >>>\n",
      "[02/10/2019 01:18:52] <<< Saving model_next to trained_models/gkb_model//epoch_17_structure_next.json... >>>\n",
      "[02/10/2019 01:18:53] <<< Model saved >>>\n",
      "[02/10/2019 01:18:53] <<< Saving model to trained_models/gkb_model//epoch_17 ... >>>\n",
      "[02/10/2019 01:18:53] <<< Saving model_init to trained_models/gkb_model//epoch_17_structure_init.json... >>>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[02/10/2019 01:18:53] <<< Saving model_next to trained_models/gkb_model//epoch_17_structure_next.json... >>>\n",
      "[02/10/2019 01:18:54] <<< Model saved >>>\n",
      "[02/10/2019 01:32:07] WARNING: parallel loaders are not implemented\n",
      "[02/10/2019 01:32:07] <<< Predicting outputs of val set >>>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sampling 200/200  -  ETA: 2s   \n",
      " Total cost of the translations: 851.135073 \t Average cost of the translations: 4.255675\n",
      "The sampling took: 583.451006 secs (Speed: 2.917255 sec/sample)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[02/10/2019 01:41:50] Prediction output 0: target_text (text)\n",
      "[02/10/2019 01:41:50] Decoding beam search prediction ...\n",
      "[02/10/2019 01:41:50] Evaluating on metric coco\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[02/10/2019 01:42:01] Computing coco scores on the val split...\n",
      "[02/10/2019 01:42:01] Bleu_1: 0.665187466155\n",
      "[02/10/2019 01:42:01] Bleu_2: 0.499850155716\n",
      "[02/10/2019 01:42:01] Bleu_3: 0.392349775338\n",
      "[02/10/2019 01:42:01] Bleu_4: 0.315993263991\n",
      "[02/10/2019 01:42:01] CIDEr: 2.68742470449\n",
      "[02/10/2019 01:42:01] METEOR: 0.416319886416\n",
      "[02/10/2019 01:42:01] ROUGE_L: 0.584895490136\n",
      "[02/10/2019 01:42:01] TER: 0.530465949821\n",
      "[02/10/2019 01:42:01] Done evaluating on metric coco\n",
      "[02/10/2019 01:42:01] <<< Progress plot saved in trained_models/gkb_model//epoch_18.jpg >>>\n",
      "[02/10/2019 01:42:01] <<< Saving model to trained_models/gkb_model//epoch_18 ... >>>\n",
      "[02/10/2019 01:42:01] <<< Saving model_init to trained_models/gkb_model//epoch_18_structure_init.json... >>>\n",
      "[02/10/2019 01:42:01] <<< Saving model_next to trained_models/gkb_model//epoch_18_structure_next.json... >>>\n",
      "[02/10/2019 01:42:01] <<< Model saved >>>\n",
      "[02/10/2019 01:42:01] <<< Saving model to trained_models/gkb_model//epoch_18 ... >>>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[02/10/2019 01:42:02] <<< Saving model_init to trained_models/gkb_model//epoch_18_structure_init.json... >>>\n",
      "[02/10/2019 01:42:02] <<< Saving model_next to trained_models/gkb_model//epoch_18_structure_next.json... >>>\n",
      "[02/10/2019 01:42:02] <<< Model saved >>>\n",
      "[02/10/2019 01:55:16] WARNING: parallel loaders are not implemented\n",
      "[02/10/2019 01:55:16] <<< Predicting outputs of val set >>>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sampling 200/200  -  ETA: 2s   \n",
      " Total cost of the translations: 807.058118 \t Average cost of the translations: 4.035291\n",
      "The sampling took: 584.514086 secs (Speed: 2.922570 sec/sample)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[02/10/2019 02:05:00] Prediction output 0: target_text (text)\n",
      "[02/10/2019 02:05:00] Decoding beam search prediction ...\n",
      "[02/10/2019 02:05:00] Evaluating on metric coco\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[02/10/2019 02:05:10] Computing coco scores on the val split...\n",
      "[02/10/2019 02:05:10] Bleu_1: 0.655881157893\n",
      "[02/10/2019 02:05:10] Bleu_2: 0.49263670113\n",
      "[02/10/2019 02:05:10] Bleu_3: 0.388171387138\n",
      "[02/10/2019 02:05:10] Bleu_4: 0.31665431869\n",
      "[02/10/2019 02:05:10] CIDEr: 2.60866675518\n",
      "[02/10/2019 02:05:10] METEOR: 0.415124627268\n",
      "[02/10/2019 02:05:10] ROUGE_L: 0.585153512933\n",
      "[02/10/2019 02:05:10] TER: 0.528375149343\n",
      "[02/10/2019 02:05:10] Done evaluating on metric coco\n",
      "[02/10/2019 02:05:11] <<< Progress plot saved in trained_models/gkb_model//epoch_19.jpg >>>\n",
      "[02/10/2019 02:05:11] <<< Saving model to trained_models/gkb_model//epoch_19 ... >>>\n",
      "[02/10/2019 02:05:11] <<< Saving model_init to trained_models/gkb_model//epoch_19_structure_init.json... >>>\n",
      "[02/10/2019 02:05:11] <<< Saving model_next to trained_models/gkb_model//epoch_19_structure_next.json... >>>\n",
      "[02/10/2019 02:05:11] <<< Model saved >>>\n",
      "[02/10/2019 02:05:11] <<< Saving model to trained_models/gkb_model//epoch_19 ... >>>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[02/10/2019 02:05:11] <<< Saving model_init to trained_models/gkb_model//epoch_19_structure_init.json... >>>\n",
      "[02/10/2019 02:05:12] <<< Saving model_next to trained_models/gkb_model//epoch_19_structure_next.json... >>>\n",
      "[02/10/2019 02:05:12] <<< Model saved >>>\n",
      "[02/10/2019 02:18:25] WARNING: parallel loaders are not implemented\n",
      "[02/10/2019 02:18:25] <<< Predicting outputs of val set >>>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sampling 200/200  -  ETA: 2s   \n",
      " Total cost of the translations: 790.550639 \t Average cost of the translations: 3.952753\n",
      "The sampling took: 571.585566 secs (Speed: 2.857928 sec/sample)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[02/10/2019 02:27:57] Prediction output 0: target_text (text)\n",
      "[02/10/2019 02:27:57] Decoding beam search prediction ...\n",
      "[02/10/2019 02:27:57] Evaluating on metric coco\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[02/10/2019 02:28:07] Computing coco scores on the val split...\n",
      "[02/10/2019 02:28:07] Bleu_1: 0.663103655112\n",
      "[02/10/2019 02:28:07] Bleu_2: 0.513340564579\n",
      "[02/10/2019 02:28:07] Bleu_3: 0.41441445449\n",
      "[02/10/2019 02:28:07] Bleu_4: 0.34068198951\n",
      "[02/10/2019 02:28:07] CIDEr: 2.90998231821\n",
      "[02/10/2019 02:28:07] METEOR: 0.413079807065\n",
      "[02/10/2019 02:28:07] ROUGE_L: 0.605395474207\n",
      "[02/10/2019 02:28:07] TER: 0.507765830346\n",
      "[02/10/2019 02:28:07] Done evaluating on metric coco\n",
      "[02/10/2019 02:28:07] <<< Progress plot saved in trained_models/gkb_model//epoch_20.jpg >>>\n",
      "[02/10/2019 02:28:07] <<< Saving model to trained_models/gkb_model//epoch_20 ... >>>\n",
      "[02/10/2019 02:28:07] <<< Saving model_init to trained_models/gkb_model//epoch_20_structure_init.json... >>>\n",
      "[02/10/2019 02:28:07] <<< Saving model_next to trained_models/gkb_model//epoch_20_structure_next.json... >>>\n",
      "[02/10/2019 02:28:08] <<< Model saved >>>\n",
      "[02/10/2019 02:28:08] <<< Saving model to trained_models/gkb_model//epoch_20 ... >>>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[02/10/2019 02:28:08] <<< Saving model_init to trained_models/gkb_model//epoch_20_structure_init.json... >>>\n",
      "[02/10/2019 02:28:08] <<< Saving model_next to trained_models/gkb_model//epoch_20_structure_next.json... >>>\n",
      "[02/10/2019 02:28:09] <<< Model saved >>>\n",
      "[02/10/2019 02:41:22] WARNING: parallel loaders are not implemented\n",
      "[02/10/2019 02:41:22] <<< Predicting outputs of val set >>>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sampling 200/200  -  ETA: 2s   \n",
      " Total cost of the translations: 780.077396 \t Average cost of the translations: 3.900387\n",
      "The sampling took: 587.118861 secs (Speed: 2.935594 sec/sample)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[02/10/2019 02:51:09] Prediction output 0: target_text (text)\n",
      "[02/10/2019 02:51:09] Decoding beam search prediction ...\n",
      "[02/10/2019 02:51:09] Evaluating on metric coco\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[02/10/2019 02:51:19] Computing coco scores on the val split...\n",
      "[02/10/2019 02:51:19] Bleu_1: 0.678173590784\n",
      "[02/10/2019 02:51:19] Bleu_2: 0.5198933174\n",
      "[02/10/2019 02:51:19] Bleu_3: 0.417505443206\n",
      "[02/10/2019 02:51:19] Bleu_4: 0.34501354692\n",
      "[02/10/2019 02:51:19] CIDEr: 2.75594096514\n",
      "[02/10/2019 02:51:19] METEOR: 0.423299430673\n",
      "[02/10/2019 02:51:19] ROUGE_L: 0.5911585123\n",
      "[02/10/2019 02:51:19] TER: 0.512544802867\n",
      "[02/10/2019 02:51:19] Done evaluating on metric coco\n",
      "[02/10/2019 02:51:19] <<< Progress plot saved in trained_models/gkb_model//epoch_21.jpg >>>\n",
      "[02/10/2019 02:51:19] <<< Saving model to trained_models/gkb_model//epoch_21 ... >>>\n",
      "[02/10/2019 02:51:19] <<< Saving model_init to trained_models/gkb_model//epoch_21_structure_init.json... >>>\n",
      "[02/10/2019 02:51:19] <<< Saving model_next to trained_models/gkb_model//epoch_21_structure_next.json... >>>\n",
      "[02/10/2019 02:51:20] <<< Model saved >>>\n",
      "[02/10/2019 02:51:20] <<< Saving model to trained_models/gkb_model//epoch_21 ... >>>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[02/10/2019 02:51:20] <<< Saving model_init to trained_models/gkb_model//epoch_21_structure_init.json... >>>\n",
      "[02/10/2019 02:51:20] <<< Saving model_next to trained_models/gkb_model//epoch_21_structure_next.json... >>>\n",
      "[02/10/2019 02:51:21] <<< Model saved >>>\n",
      "[02/10/2019 03:04:34] WARNING: parallel loaders are not implemented\n",
      "[02/10/2019 03:04:34] <<< Predicting outputs of val set >>>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sampling 200/200  -  ETA: 2s   \n",
      " Total cost of the translations: 732.720208 \t Average cost of the translations: 3.663601\n",
      "The sampling took: 578.613575 secs (Speed: 2.893068 sec/sample)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[02/10/2019 03:14:13] Prediction output 0: target_text (text)\n",
      "[02/10/2019 03:14:13] Decoding beam search prediction ...\n",
      "[02/10/2019 03:14:13] Evaluating on metric coco\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[02/10/2019 03:14:23] Computing coco scores on the val split...\n",
      "[02/10/2019 03:14:23] Bleu_1: 0.670403922939\n",
      "[02/10/2019 03:14:23] Bleu_2: 0.512959713916\n",
      "[02/10/2019 03:14:23] Bleu_3: 0.412620455318\n",
      "[02/10/2019 03:14:23] Bleu_4: 0.342233361188\n",
      "[02/10/2019 03:14:23] CIDEr: 2.85388391266\n",
      "[02/10/2019 03:14:23] METEOR: 0.423203976045\n",
      "[02/10/2019 03:14:23] ROUGE_L: 0.597305145415\n",
      "[02/10/2019 03:14:23] TER: 0.515830346476\n",
      "[02/10/2019 03:14:23] Done evaluating on metric coco\n",
      "[02/10/2019 03:14:23] <<< Progress plot saved in trained_models/gkb_model//epoch_22.jpg >>>\n",
      "[02/10/2019 03:14:23] <<< Saving model to trained_models/gkb_model//epoch_22 ... >>>\n",
      "[02/10/2019 03:14:23] <<< Saving model_init to trained_models/gkb_model//epoch_22_structure_init.json... >>>\n",
      "[02/10/2019 03:14:23] <<< Saving model_next to trained_models/gkb_model//epoch_22_structure_next.json... >>>\n",
      "[02/10/2019 03:14:24] <<< Model saved >>>\n",
      "[02/10/2019 03:14:24] <<< Saving model to trained_models/gkb_model//epoch_22 ... >>>\n",
      "[02/10/2019 03:14:24] <<< Saving model_init to trained_models/gkb_model//epoch_22_structure_init.json... >>>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[02/10/2019 03:14:24] <<< Saving model_next to trained_models/gkb_model//epoch_22_structure_next.json... >>>\n",
      "[02/10/2019 03:14:24] <<< Model saved >>>\n",
      "[02/10/2019 03:27:38] WARNING: parallel loaders are not implemented\n",
      "[02/10/2019 03:27:38] <<< Predicting outputs of val set >>>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sampling 200/200  -  ETA: 2s   \n",
      " Total cost of the translations: 711.118520 \t Average cost of the translations: 3.555593\n",
      "The sampling took: 584.120833 secs (Speed: 2.920604 sec/sample)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[02/10/2019 03:37:22] Prediction output 0: target_text (text)\n",
      "[02/10/2019 03:37:22] Decoding beam search prediction ...\n",
      "[02/10/2019 03:37:22] Evaluating on metric coco\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[02/10/2019 03:37:32] Computing coco scores on the val split...\n",
      "[02/10/2019 03:37:32] Bleu_1: 0.668828312589\n",
      "[02/10/2019 03:37:32] Bleu_2: 0.503984683702\n",
      "[02/10/2019 03:37:32] Bleu_3: 0.397764223204\n",
      "[02/10/2019 03:37:32] Bleu_4: 0.323023320402\n",
      "[02/10/2019 03:37:32] CIDEr: 2.68014256929\n",
      "[02/10/2019 03:37:32] METEOR: 0.4231572846\n",
      "[02/10/2019 03:37:32] ROUGE_L: 0.584182830752\n",
      "[02/10/2019 03:37:32] TER: 0.535244922342\n",
      "[02/10/2019 03:37:32] Done evaluating on metric coco\n",
      "[02/10/2019 03:37:32] <<< Progress plot saved in trained_models/gkb_model//epoch_23.jpg >>>\n",
      "[02/10/2019 03:37:32] <<< Saving model to trained_models/gkb_model//epoch_23 ... >>>\n",
      "[02/10/2019 03:37:32] <<< Saving model_init to trained_models/gkb_model//epoch_23_structure_init.json... >>>\n",
      "[02/10/2019 03:37:33] <<< Saving model_next to trained_models/gkb_model//epoch_23_structure_next.json... >>>\n",
      "[02/10/2019 03:37:33] <<< Model saved >>>\n",
      "[02/10/2019 03:37:33] <<< Saving model to trained_models/gkb_model//epoch_23 ... >>>\n",
      "[02/10/2019 03:37:33] <<< Saving model_init to trained_models/gkb_model//epoch_23_structure_init.json... >>>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[02/10/2019 03:37:33] <<< Saving model_next to trained_models/gkb_model//epoch_23_structure_next.json... >>>\n",
      "[02/10/2019 03:37:34] <<< Model saved >>>\n",
      "[02/10/2019 03:50:47] WARNING: parallel loaders are not implemented\n",
      "[02/10/2019 03:50:47] <<< Predicting outputs of val set >>>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sampling 200/200  -  ETA: 2s   \n",
      " Total cost of the translations: 702.200000 \t Average cost of the translations: 3.511000\n",
      "The sampling took: 581.444946 secs (Speed: 2.907225 sec/sample)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[02/10/2019 04:00:28] Prediction output 0: target_text (text)\n",
      "[02/10/2019 04:00:28] Decoding beam search prediction ...\n",
      "[02/10/2019 04:00:28] Evaluating on metric coco\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[02/10/2019 04:00:38] Computing coco scores on the val split...\n",
      "[02/10/2019 04:00:38] Bleu_1: 0.678950597771\n",
      "[02/10/2019 04:00:38] Bleu_2: 0.516430549805\n",
      "[02/10/2019 04:00:38] Bleu_3: 0.414824456429\n",
      "[02/10/2019 04:00:38] Bleu_4: 0.342866667286\n",
      "[02/10/2019 04:00:38] CIDEr: 2.75049285428\n",
      "[02/10/2019 04:00:38] METEOR: 0.424010365446\n",
      "[02/10/2019 04:00:38] ROUGE_L: 0.594216405551\n",
      "[02/10/2019 04:00:38] TER: 0.522102747909\n",
      "[02/10/2019 04:00:38] Done evaluating on metric coco\n",
      "[02/10/2019 04:00:39] <<< Progress plot saved in trained_models/gkb_model//epoch_24.jpg >>>\n",
      "[02/10/2019 04:00:39] <<< Saving model to trained_models/gkb_model//epoch_24 ... >>>\n",
      "[02/10/2019 04:00:39] <<< Saving model_init to trained_models/gkb_model//epoch_24_structure_init.json... >>>\n",
      "[02/10/2019 04:00:39] <<< Saving model_next to trained_models/gkb_model//epoch_24_structure_next.json... >>>\n",
      "[02/10/2019 04:00:39] <<< Model saved >>>\n",
      "[02/10/2019 04:00:39] <<< Saving model to trained_models/gkb_model//epoch_24 ... >>>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[02/10/2019 04:00:39] <<< Saving model_init to trained_models/gkb_model//epoch_24_structure_init.json... >>>\n",
      "[02/10/2019 04:00:40] <<< Saving model_next to trained_models/gkb_model//epoch_24_structure_next.json... >>>\n",
      "[02/10/2019 04:00:40] <<< Model saved >>>\n",
      "[02/10/2019 04:13:54] WARNING: parallel loaders are not implemented\n",
      "[02/10/2019 04:13:54] <<< Predicting outputs of val set >>>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sampling 200/200  -  ETA: 2s   \n",
      " Total cost of the translations: 674.583386 \t Average cost of the translations: 3.372917\n",
      "The sampling took: 573.785483 secs (Speed: 2.868927 sec/sample)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[02/10/2019 04:23:27] Prediction output 0: target_text (text)\n",
      "[02/10/2019 04:23:27] Decoding beam search prediction ...\n",
      "[02/10/2019 04:23:27] Evaluating on metric coco\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[02/10/2019 04:23:38] Computing coco scores on the val split...\n",
      "[02/10/2019 04:23:38] Bleu_1: 0.680808801245\n",
      "[02/10/2019 04:23:38] Bleu_2: 0.518190950522\n",
      "[02/10/2019 04:23:38] Bleu_3: 0.414942813427\n",
      "[02/10/2019 04:23:38] Bleu_4: 0.343019960174\n",
      "[02/10/2019 04:23:38] CIDEr: 2.87297592645\n",
      "[02/10/2019 04:23:38] METEOR: 0.429473656994\n",
      "[02/10/2019 04:23:38] ROUGE_L: 0.592743731439\n",
      "[02/10/2019 04:23:38] TER: 0.51164874552\n",
      "[02/10/2019 04:23:38] Done evaluating on metric coco\n",
      "[02/10/2019 04:23:38] <<< Progress plot saved in trained_models/gkb_model//epoch_25.jpg >>>\n",
      "[02/10/2019 04:23:38] <<< Saving model to trained_models/gkb_model//epoch_25 ... >>>\n",
      "[02/10/2019 04:23:38] <<< Saving model_init to trained_models/gkb_model//epoch_25_structure_init.json... >>>\n",
      "[02/10/2019 04:23:38] <<< Saving model_next to trained_models/gkb_model//epoch_25_structure_next.json... >>>\n",
      "[02/10/2019 04:23:39] <<< Model saved >>>\n",
      "[02/10/2019 04:23:39] <<< Saving model to trained_models/gkb_model//epoch_25 ... >>>\n",
      "[02/10/2019 04:23:39] <<< Saving model_init to trained_models/gkb_model//epoch_25_structure_init.json... >>>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[02/10/2019 04:23:39] <<< Saving model_next to trained_models/gkb_model//epoch_25_structure_next.json... >>>\n",
      "[02/10/2019 04:23:39] <<< Model saved >>>\n",
      "[02/10/2019 04:36:55] WARNING: parallel loaders are not implemented\n",
      "[02/10/2019 04:36:55] <<< Predicting outputs of val set >>>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sampling 200/200  -  ETA: 5s   \n",
      " Total cost of the translations: 649.942578 \t Average cost of the translations: 3.249713\n",
      "The sampling took: 1084.028917 secs (Speed: 5.420145 sec/sample)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[02/10/2019 04:54:59] Prediction output 0: target_text (text)\n",
      "[02/10/2019 04:54:59] Decoding beam search prediction ...\n",
      "[02/10/2019 04:54:59] Evaluating on metric coco\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[02/10/2019 04:55:09] Computing coco scores on the val split...\n",
      "[02/10/2019 04:55:09] Bleu_1: 0.683390295701\n",
      "[02/10/2019 04:55:09] Bleu_2: 0.520846809492\n",
      "[02/10/2019 04:55:09] Bleu_3: 0.417804539301\n",
      "[02/10/2019 04:55:09] Bleu_4: 0.34449710506\n",
      "[02/10/2019 04:55:09] CIDEr: 2.79463891279\n",
      "[02/10/2019 04:55:09] METEOR: 0.425844931082\n",
      "[02/10/2019 04:55:09] ROUGE_L: 0.59048033645\n",
      "[02/10/2019 04:55:09] TER: 0.51164874552\n",
      "[02/10/2019 04:55:09] Done evaluating on metric coco\n",
      "[02/10/2019 04:55:09] <<< Progress plot saved in trained_models/gkb_model//epoch_26.jpg >>>\n",
      "[02/10/2019 04:55:09] <<< Saving model to trained_models/gkb_model//epoch_26 ... >>>\n",
      "[02/10/2019 04:55:09] <<< Saving model_init to trained_models/gkb_model//epoch_26_structure_init.json... >>>\n",
      "[02/10/2019 04:55:10] <<< Saving model_next to trained_models/gkb_model//epoch_26_structure_next.json... >>>\n",
      "[02/10/2019 04:55:10] <<< Model saved >>>\n",
      "[02/10/2019 04:55:10] <<< Saving model to trained_models/gkb_model//epoch_26 ... >>>\n",
      "[02/10/2019 04:55:10] <<< Saving model_init to trained_models/gkb_model//epoch_26_structure_init.json... >>>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[02/10/2019 04:55:10] <<< Saving model_next to trained_models/gkb_model//epoch_26_structure_next.json... >>>\n",
      "[02/10/2019 04:55:11] <<< Model saved >>>\n",
      "[02/10/2019 05:09:28] WARNING: parallel loaders are not implemented\n",
      "[02/10/2019 05:09:28] <<< Predicting outputs of val set >>>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sampling 200/200  -  ETA: 2s   \n",
      " Total cost of the translations: 641.368665 \t Average cost of the translations: 3.206843\n",
      "The sampling took: 582.986566 secs (Speed: 2.914933 sec/sample)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[02/10/2019 05:19:11] Prediction output 0: target_text (text)\n",
      "[02/10/2019 05:19:11] Decoding beam search prediction ...\n",
      "[02/10/2019 05:19:11] Evaluating on metric coco\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[02/10/2019 05:19:20] Computing coco scores on the val split...\n",
      "[02/10/2019 05:19:20] Bleu_1: 0.678429510341\n",
      "[02/10/2019 05:19:20] Bleu_2: 0.507366793416\n",
      "[02/10/2019 05:19:20] Bleu_3: 0.401209456676\n",
      "[02/10/2019 05:19:20] Bleu_4: 0.32697085041\n",
      "[02/10/2019 05:19:20] CIDEr: 2.61415382235\n",
      "[02/10/2019 05:19:20] METEOR: 0.424734664281\n",
      "[02/10/2019 05:19:20] ROUGE_L: 0.579904967862\n",
      "[02/10/2019 05:19:20] TER: 0.531660692951\n",
      "[02/10/2019 05:19:21] Done evaluating on metric coco\n",
      "[02/10/2019 05:19:21] <<< Progress plot saved in trained_models/gkb_model//epoch_27.jpg >>>\n",
      "[02/10/2019 05:19:21] <<< Saving model to trained_models/gkb_model//epoch_27 ... >>>\n",
      "[02/10/2019 05:19:21] <<< Saving model_init to trained_models/gkb_model//epoch_27_structure_init.json... >>>\n",
      "[02/10/2019 05:19:21] <<< Saving model_next to trained_models/gkb_model//epoch_27_structure_next.json... >>>\n",
      "[02/10/2019 05:19:21] <<< Model saved >>>\n",
      "[02/10/2019 05:19:21] <<< Saving model to trained_models/gkb_model//epoch_27 ... >>>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[02/10/2019 05:19:22] <<< Saving model_init to trained_models/gkb_model//epoch_27_structure_init.json... >>>\n",
      "[02/10/2019 05:19:22] <<< Saving model_next to trained_models/gkb_model//epoch_27_structure_next.json... >>>\n",
      "[02/10/2019 05:19:22] <<< Model saved >>>\n",
      "[02/10/2019 05:32:36] WARNING: parallel loaders are not implemented\n",
      "[02/10/2019 05:32:36] <<< Predicting outputs of val set >>>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sampling 200/200  -  ETA: 2s   \n",
      " Total cost of the translations: 616.962784 \t Average cost of the translations: 3.084814\n",
      "The sampling took: 584.452935 secs (Speed: 2.922265 sec/sample)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[02/10/2019 05:42:21] Prediction output 0: target_text (text)\n",
      "[02/10/2019 05:42:21] Decoding beam search prediction ...\n",
      "[02/10/2019 05:42:21] Evaluating on metric coco\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[02/10/2019 05:42:31] Computing coco scores on the val split...\n",
      "[02/10/2019 05:42:31] Bleu_1: 0.682665487752\n",
      "[02/10/2019 05:42:31] Bleu_2: 0.519090031607\n",
      "[02/10/2019 05:42:31] Bleu_3: 0.41353397528\n",
      "[02/10/2019 05:42:31] Bleu_4: 0.339880946156\n",
      "[02/10/2019 05:42:31] CIDEr: 2.8152724599\n",
      "[02/10/2019 05:42:31] METEOR: 0.42904680843\n",
      "[02/10/2019 05:42:31] ROUGE_L: 0.585546327571\n",
      "[02/10/2019 05:42:31] TER: 0.522401433692\n",
      "[02/10/2019 05:42:31] Done evaluating on metric coco\n",
      "[02/10/2019 05:42:31] <<< Progress plot saved in trained_models/gkb_model//epoch_28.jpg >>>\n",
      "[02/10/2019 05:42:31] <<< Saving model to trained_models/gkb_model//epoch_28 ... >>>\n",
      "[02/10/2019 05:42:31] <<< Saving model_init to trained_models/gkb_model//epoch_28_structure_init.json... >>>\n",
      "[02/10/2019 05:42:31] <<< Saving model_next to trained_models/gkb_model//epoch_28_structure_next.json... >>>\n",
      "[02/10/2019 05:42:32] <<< Model saved >>>\n",
      "[02/10/2019 05:42:32] <<< Saving model to trained_models/gkb_model//epoch_28 ... >>>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[02/10/2019 05:42:32] <<< Saving model_init to trained_models/gkb_model//epoch_28_structure_init.json... >>>\n",
      "[02/10/2019 05:42:32] <<< Saving model_next to trained_models/gkb_model//epoch_28_structure_next.json... >>>\n",
      "[02/10/2019 05:42:33] <<< Model saved >>>\n",
      "[02/10/2019 05:55:47] WARNING: parallel loaders are not implemented\n",
      "[02/10/2019 05:55:47] <<< Predicting outputs of val set >>>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sampling 200/200  -  ETA: 2s   \n",
      " Total cost of the translations: 599.083937 \t Average cost of the translations: 2.995420\n",
      "The sampling took: 572.928115 secs (Speed: 2.864641 sec/sample)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[02/10/2019 06:05:20] Prediction output 0: target_text (text)\n",
      "[02/10/2019 06:05:20] Decoding beam search prediction ...\n",
      "[02/10/2019 06:05:20] Evaluating on metric coco\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[02/10/2019 06:05:30] Computing coco scores on the val split...\n",
      "[02/10/2019 06:05:30] Bleu_1: 0.673713635141\n",
      "[02/10/2019 06:05:30] Bleu_2: 0.508353554025\n",
      "[02/10/2019 06:05:30] Bleu_3: 0.403377691504\n",
      "[02/10/2019 06:05:30] Bleu_4: 0.331250893162\n",
      "[02/10/2019 06:05:30] CIDEr: 2.70587606427\n",
      "[02/10/2019 06:05:30] METEOR: 0.419617878477\n",
      "[02/10/2019 06:05:30] ROUGE_L: 0.585393243495\n",
      "[02/10/2019 06:05:30] TER: 0.525089605735\n",
      "[02/10/2019 06:05:30] Done evaluating on metric coco\n",
      "[02/10/2019 06:05:30] <<< Progress plot saved in trained_models/gkb_model//epoch_29.jpg >>>\n",
      "[02/10/2019 06:05:30] <<< Saving model to trained_models/gkb_model//epoch_29 ... >>>\n",
      "[02/10/2019 06:05:30] <<< Saving model_init to trained_models/gkb_model//epoch_29_structure_init.json... >>>\n",
      "[02/10/2019 06:05:30] <<< Saving model_next to trained_models/gkb_model//epoch_29_structure_next.json... >>>\n",
      "[02/10/2019 06:05:31] <<< Model saved >>>\n",
      "[02/10/2019 06:05:31] <<< Saving model to trained_models/gkb_model//epoch_29 ... >>>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[02/10/2019 06:05:31] <<< Saving model_init to trained_models/gkb_model//epoch_29_structure_init.json... >>>\n",
      "[02/10/2019 06:05:31] <<< Saving model_next to trained_models/gkb_model//epoch_29_structure_next.json... >>>\n",
      "[02/10/2019 06:05:32] <<< Model saved >>>\n",
      "[02/10/2019 06:18:45] WARNING: parallel loaders are not implemented\n",
      "[02/10/2019 06:18:45] <<< Predicting outputs of val set >>>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sampling 200/200  -  ETA: 2s   \n",
      " Total cost of the translations: 593.381569 \t Average cost of the translations: 2.966908\n",
      "The sampling took: 574.268576 secs (Speed: 2.871343 sec/sample)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[02/10/2019 06:28:20] Prediction output 0: target_text (text)\n",
      "[02/10/2019 06:28:20] Decoding beam search prediction ...\n",
      "[02/10/2019 06:28:20] Evaluating on metric coco\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[02/10/2019 06:28:30] Computing coco scores on the val split...\n",
      "[02/10/2019 06:28:30] Bleu_1: 0.675048717479\n",
      "[02/10/2019 06:28:30] Bleu_2: 0.511176253585\n",
      "[02/10/2019 06:28:30] Bleu_3: 0.407765517575\n",
      "[02/10/2019 06:28:30] Bleu_4: 0.336707081192\n",
      "[02/10/2019 06:28:30] CIDEr: 2.73610526385\n",
      "[02/10/2019 06:28:30] METEOR: 0.424798490335\n",
      "[02/10/2019 06:28:30] ROUGE_L: 0.585537397201\n",
      "[02/10/2019 06:28:30] TER: 0.527777777778\n",
      "[02/10/2019 06:28:30] Done evaluating on metric coco\n",
      "[02/10/2019 06:28:30] <<< Progress plot saved in trained_models/gkb_model//epoch_30.jpg >>>\n",
      "[02/10/2019 06:28:30] <<< Saving model to trained_models/gkb_model//epoch_30 ... >>>\n",
      "[02/10/2019 06:28:30] <<< Saving model_init to trained_models/gkb_model//epoch_30_structure_init.json... >>>\n",
      "[02/10/2019 06:28:30] <<< Saving model_next to trained_models/gkb_model//epoch_30_structure_next.json... >>>\n",
      "[02/10/2019 06:28:31] <<< Model saved >>>\n",
      "[02/10/2019 06:28:31] <<< Saving model to trained_models/gkb_model//epoch_30 ... >>>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[02/10/2019 06:28:31] <<< Saving model_init to trained_models/gkb_model//epoch_30_structure_init.json... >>>\n",
      "[02/10/2019 06:28:31] <<< Saving model_next to trained_models/gkb_model//epoch_30_structure_next.json... >>>\n",
      "[02/10/2019 06:28:32] <<< Model saved >>>\n",
      "[02/10/2019 06:44:08] WARNING: parallel loaders are not implemented\n",
      "[02/10/2019 06:44:08] <<< Predicting outputs of val set >>>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sampling 200/200  -  ETA: 5s   \n",
      " Total cost of the translations: 582.800835 \t Average cost of the translations: 2.914004\n",
      "The sampling took: 1117.499346 secs (Speed: 5.587497 sec/sample)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[02/10/2019 07:02:45] Prediction output 0: target_text (text)\n",
      "[02/10/2019 07:02:45] Decoding beam search prediction ...\n",
      "[02/10/2019 07:02:45] Evaluating on metric coco\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[02/10/2019 07:02:55] Computing coco scores on the val split...\n",
      "[02/10/2019 07:02:55] Bleu_1: 0.67992056421\n",
      "[02/10/2019 07:02:55] Bleu_2: 0.517631810262\n",
      "[02/10/2019 07:02:55] Bleu_3: 0.414914237559\n",
      "[02/10/2019 07:02:55] Bleu_4: 0.344190171367\n",
      "[02/10/2019 07:02:55] CIDEr: 2.86782107314\n",
      "[02/10/2019 07:02:55] METEOR: 0.428197838871\n",
      "[02/10/2019 07:02:55] ROUGE_L: 0.588605979386\n",
      "[02/10/2019 07:02:55] TER: 0.523596176822\n",
      "[02/10/2019 07:02:55] Done evaluating on metric coco\n",
      "[02/10/2019 07:02:56] <<< Progress plot saved in trained_models/gkb_model//epoch_31.jpg >>>\n",
      "[02/10/2019 07:02:56] <<< Saving model to trained_models/gkb_model//epoch_31 ... >>>\n",
      "[02/10/2019 07:02:56] <<< Saving model_init to trained_models/gkb_model//epoch_31_structure_init.json... >>>\n",
      "[02/10/2019 07:02:56] <<< Saving model_next to trained_models/gkb_model//epoch_31_structure_next.json... >>>\n",
      "[02/10/2019 07:02:56] <<< Model saved >>>\n",
      "[02/10/2019 07:02:56] <<< Saving model to trained_models/gkb_model//epoch_31 ... >>>\n",
      "[02/10/2019 07:02:56] <<< Saving model_init to trained_models/gkb_model//epoch_31_structure_init.json... >>>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[02/10/2019 07:02:57] <<< Saving model_next to trained_models/gkb_model//epoch_31_structure_next.json... >>>\n",
      "[02/10/2019 07:02:57] <<< Model saved >>>\n",
      "[02/10/2019 07:22:51] WARNING: parallel loaders are not implemented\n",
      "[02/10/2019 07:22:51] <<< Predicting outputs of val set >>>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sampling 200/200  -  ETA: 5s   \n",
      " Total cost of the translations: 570.065742 \t Average cost of the translations: 2.850329\n",
      "The sampling took: 1101.033974 secs (Speed: 5.505170 sec/sample)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[02/10/2019 07:41:12] Prediction output 0: target_text (text)\n",
      "[02/10/2019 07:41:12] Decoding beam search prediction ...\n",
      "[02/10/2019 07:41:12] Evaluating on metric coco\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[02/10/2019 07:41:22] Computing coco scores on the val split...\n",
      "[02/10/2019 07:41:22] Bleu_1: 0.690668772344\n",
      "[02/10/2019 07:41:22] Bleu_2: 0.53086541925\n",
      "[02/10/2019 07:41:22] Bleu_3: 0.424708872543\n",
      "[02/10/2019 07:41:22] Bleu_4: 0.351112060163\n",
      "[02/10/2019 07:41:22] CIDEr: 2.83534231927\n",
      "[02/10/2019 07:41:22] METEOR: 0.430929697441\n",
      "[02/10/2019 07:41:22] ROUGE_L: 0.590947621199\n",
      "[02/10/2019 07:41:22] TER: 0.511350059737\n",
      "[02/10/2019 07:41:22] Done evaluating on metric coco\n",
      "[02/10/2019 07:41:22] <<< Progress plot saved in trained_models/gkb_model//epoch_32.jpg >>>\n",
      "[02/10/2019 07:41:22] <<< Saving model to trained_models/gkb_model//epoch_32 ... >>>\n",
      "[02/10/2019 07:41:23] <<< Saving model_init to trained_models/gkb_model//epoch_32_structure_init.json... >>>\n",
      "[02/10/2019 07:41:23] <<< Saving model_next to trained_models/gkb_model//epoch_32_structure_next.json... >>>\n",
      "[02/10/2019 07:41:23] <<< Model saved >>>\n",
      "[02/10/2019 07:41:23] <<< Saving model to trained_models/gkb_model//epoch_32 ... >>>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[02/10/2019 07:41:23] <<< Saving model_init to trained_models/gkb_model//epoch_32_structure_init.json... >>>\n",
      "[02/10/2019 07:41:24] <<< Saving model_next to trained_models/gkb_model//epoch_32_structure_next.json... >>>\n",
      "[02/10/2019 07:41:24] <<< Model saved >>>\n",
      "[02/10/2019 08:00:58] WARNING: parallel loaders are not implemented\n",
      "[02/10/2019 08:00:58] <<< Predicting outputs of val set >>>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sampling 200/200  -  ETA: 4s   \n",
      " Total cost of the translations: 540.718678 \t Average cost of the translations: 2.703593\n",
      "The sampling took: 1002.968071 secs (Speed: 5.014840 sec/sample)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[02/10/2019 08:17:41] Prediction output 0: target_text (text)\n",
      "[02/10/2019 08:17:41] Decoding beam search prediction ...\n",
      "[02/10/2019 08:17:41] Evaluating on metric coco\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[02/10/2019 08:17:52] Computing coco scores on the val split...\n",
      "[02/10/2019 08:17:52] Bleu_1: 0.686694995483\n",
      "[02/10/2019 08:17:52] Bleu_2: 0.51803138059\n",
      "[02/10/2019 08:17:52] Bleu_3: 0.410456992436\n",
      "[02/10/2019 08:17:52] Bleu_4: 0.337114224362\n",
      "[02/10/2019 08:17:52] CIDEr: 2.65413886603\n",
      "[02/10/2019 08:17:52] METEOR: 0.427262669727\n",
      "[02/10/2019 08:17:52] ROUGE_L: 0.590373338879\n",
      "[02/10/2019 08:17:52] TER: 0.521804062127\n",
      "[02/10/2019 08:17:52] Done evaluating on metric coco\n",
      "[02/10/2019 08:17:52] <<< Progress plot saved in trained_models/gkb_model//epoch_33.jpg >>>\n",
      "[02/10/2019 08:17:52] <<< Saving model to trained_models/gkb_model//epoch_33 ... >>>\n",
      "[02/10/2019 08:17:52] <<< Saving model_init to trained_models/gkb_model//epoch_33_structure_init.json... >>>\n",
      "[02/10/2019 08:17:52] <<< Saving model_next to trained_models/gkb_model//epoch_33_structure_next.json... >>>\n",
      "[02/10/2019 08:17:52] <<< Model saved >>>\n",
      "[02/10/2019 08:17:52] <<< Saving model to trained_models/gkb_model//epoch_33 ... >>>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[02/10/2019 08:17:53] <<< Saving model_init to trained_models/gkb_model//epoch_33_structure_init.json... >>>\n",
      "[02/10/2019 08:17:53] <<< Saving model_next to trained_models/gkb_model//epoch_33_structure_next.json... >>>\n",
      "[02/10/2019 08:17:54] <<< Model saved >>>\n",
      "[02/10/2019 08:37:19] WARNING: parallel loaders are not implemented\n",
      "[02/10/2019 08:37:19] <<< Predicting outputs of val set >>>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sampling 200/200  -  ETA: 5s   \n",
      " Total cost of the translations: 518.755058 \t Average cost of the translations: 2.593775\n",
      "The sampling took: 1082.417587 secs (Speed: 5.412088 sec/sample)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[02/10/2019 08:55:22] Prediction output 0: target_text (text)\n",
      "[02/10/2019 08:55:22] Decoding beam search prediction ...\n",
      "[02/10/2019 08:55:22] Evaluating on metric coco\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[02/10/2019 08:55:32] Computing coco scores on the val split...\n",
      "[02/10/2019 08:55:32] Bleu_1: 0.683616009076\n",
      "[02/10/2019 08:55:32] Bleu_2: 0.524052506474\n",
      "[02/10/2019 08:55:32] Bleu_3: 0.42175656068\n",
      "[02/10/2019 08:55:32] Bleu_4: 0.350927900819\n",
      "[02/10/2019 08:55:32] CIDEr: 2.79975880026\n",
      "[02/10/2019 08:55:32] METEOR: 0.428136122753\n",
      "[02/10/2019 08:55:32] ROUGE_L: 0.59347825993\n",
      "[02/10/2019 08:55:32] TER: 0.508363201912\n",
      "[02/10/2019 08:55:32] Done evaluating on metric coco\n",
      "[02/10/2019 08:55:32] <<< Progress plot saved in trained_models/gkb_model//epoch_34.jpg >>>\n",
      "[02/10/2019 08:55:32] <<< Saving model to trained_models/gkb_model//epoch_34 ... >>>\n",
      "[02/10/2019 08:55:32] <<< Saving model_init to trained_models/gkb_model//epoch_34_structure_init.json... >>>\n",
      "[02/10/2019 08:55:32] <<< Saving model_next to trained_models/gkb_model//epoch_34_structure_next.json... >>>\n",
      "[02/10/2019 08:55:33] <<< Model saved >>>\n",
      "[02/10/2019 08:55:33] <<< Saving model to trained_models/gkb_model//epoch_34 ... >>>\n",
      "[02/10/2019 08:55:33] <<< Saving model_init to trained_models/gkb_model//epoch_34_structure_init.json... >>>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[02/10/2019 08:55:33] <<< Saving model_next to trained_models/gkb_model//epoch_34_structure_next.json... >>>\n",
      "[02/10/2019 08:55:34] <<< Model saved >>>\n",
      "[02/10/2019 09:15:22] WARNING: parallel loaders are not implemented\n",
      "[02/10/2019 09:15:22] <<< Predicting outputs of val set >>>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sampling 200/200  -  ETA: 5s   \n",
      " Total cost of the translations: 525.083423 \t Average cost of the translations: 2.625417\n",
      "The sampling took: 1125.506295 secs (Speed: 5.627531 sec/sample)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[02/10/2019 09:34:07] Prediction output 0: target_text (text)\n",
      "[02/10/2019 09:34:07] Decoding beam search prediction ...\n",
      "[02/10/2019 09:34:07] Evaluating on metric coco\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[02/10/2019 09:34:17] Computing coco scores on the val split...\n",
      "[02/10/2019 09:34:17] Bleu_1: 0.685465117396\n",
      "[02/10/2019 09:34:17] Bleu_2: 0.512066498626\n",
      "[02/10/2019 09:34:17] Bleu_3: 0.400931663565\n",
      "[02/10/2019 09:34:17] Bleu_4: 0.324366841901\n",
      "[02/10/2019 09:34:17] CIDEr: 2.6808422873\n",
      "[02/10/2019 09:34:17] METEOR: 0.424612267545\n",
      "[02/10/2019 09:34:17] ROUGE_L: 0.579458292569\n",
      "[02/10/2019 09:34:17] TER: 0.528375149343\n",
      "[02/10/2019 09:34:17] Done evaluating on metric coco\n",
      "[02/10/2019 09:34:17] <<< Progress plot saved in trained_models/gkb_model//epoch_35.jpg >>>\n",
      "[02/10/2019 09:34:17] <<< Saving model to trained_models/gkb_model//epoch_35 ... >>>\n",
      "[02/10/2019 09:34:18] <<< Saving model_init to trained_models/gkb_model//epoch_35_structure_init.json... >>>\n",
      "[02/10/2019 09:34:18] <<< Saving model_next to trained_models/gkb_model//epoch_35_structure_next.json... >>>\n",
      "[02/10/2019 09:34:18] <<< Model saved >>>\n",
      "[02/10/2019 09:34:18] <<< Saving model to trained_models/gkb_model//epoch_35 ... >>>\n",
      "[02/10/2019 09:34:18] <<< Saving model_init to trained_models/gkb_model//epoch_35_structure_init.json... >>>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[02/10/2019 09:34:19] <<< Saving model_next to trained_models/gkb_model//epoch_35_structure_next.json... >>>\n",
      "[02/10/2019 09:34:19] <<< Model saved >>>\n",
      "[02/10/2019 09:54:15] WARNING: parallel loaders are not implemented\n",
      "[02/10/2019 09:54:15] <<< Predicting outputs of val set >>>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sampling 200/200  -  ETA: 3s   \n",
      " Total cost of the translations: 523.288505 \t Average cost of the translations: 2.616443\n",
      "The sampling took: 663.110233 secs (Speed: 3.315551 sec/sample)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[02/10/2019 10:05:18] Prediction output 0: target_text (text)\n",
      "[02/10/2019 10:05:18] Decoding beam search prediction ...\n",
      "[02/10/2019 10:05:18] Evaluating on metric coco\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[02/10/2019 10:05:28] Computing coco scores on the val split...\n",
      "[02/10/2019 10:05:28] Bleu_1: 0.695062037811\n",
      "[02/10/2019 10:05:28] Bleu_2: 0.524670499818\n",
      "[02/10/2019 10:05:28] Bleu_3: 0.415768302797\n",
      "[02/10/2019 10:05:28] Bleu_4: 0.340005721898\n",
      "[02/10/2019 10:05:28] CIDEr: 2.69864478608\n",
      "[02/10/2019 10:05:28] METEOR: 0.427004555463\n",
      "[02/10/2019 10:05:28] ROUGE_L: 0.583095219229\n",
      "[02/10/2019 10:05:28] TER: 0.529569892473\n",
      "[02/10/2019 10:05:28] Done evaluating on metric coco\n",
      "[02/10/2019 10:05:29] <<< Progress plot saved in trained_models/gkb_model//epoch_36.jpg >>>\n",
      "[02/10/2019 10:05:29] <<< Saving model to trained_models/gkb_model//epoch_36 ... >>>\n",
      "[02/10/2019 10:05:29] <<< Saving model_init to trained_models/gkb_model//epoch_36_structure_init.json... >>>\n",
      "[02/10/2019 10:05:29] <<< Saving model_next to trained_models/gkb_model//epoch_36_structure_next.json... >>>\n",
      "[02/10/2019 10:05:29] <<< Model saved >>>\n",
      "[02/10/2019 10:05:29] <<< Saving model to trained_models/gkb_model//epoch_36 ... >>>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[02/10/2019 10:05:29] <<< Saving model_init to trained_models/gkb_model//epoch_36_structure_init.json... >>>\n",
      "[02/10/2019 10:05:30] <<< Saving model_next to trained_models/gkb_model//epoch_36_structure_next.json... >>>\n",
      "[02/10/2019 10:05:30] <<< Model saved >>>\n",
      "[02/10/2019 10:18:44] WARNING: parallel loaders are not implemented\n",
      "[02/10/2019 10:18:44] <<< Predicting outputs of val set >>>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sampling 200/200  -  ETA: 2s   \n",
      " Total cost of the translations: 519.039696 \t Average cost of the translations: 2.595198\n",
      "The sampling took: 580.185338 secs (Speed: 2.900927 sec/sample)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[02/10/2019 10:28:24] Prediction output 0: target_text (text)\n",
      "[02/10/2019 10:28:24] Decoding beam search prediction ...\n",
      "[02/10/2019 10:28:24] Evaluating on metric coco\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[02/10/2019 10:28:34] Computing coco scores on the val split...\n",
      "[02/10/2019 10:28:34] Bleu_1: 0.680595678484\n",
      "[02/10/2019 10:28:34] Bleu_2: 0.511533844906\n",
      "[02/10/2019 10:28:34] Bleu_3: 0.405996185357\n",
      "[02/10/2019 10:28:34] Bleu_4: 0.332608951768\n",
      "[02/10/2019 10:28:34] CIDEr: 2.64193581522\n",
      "[02/10/2019 10:28:34] METEOR: 0.426142545685\n",
      "[02/10/2019 10:28:34] ROUGE_L: 0.576462746304\n",
      "[02/10/2019 10:28:34] TER: 0.535543608124\n",
      "[02/10/2019 10:28:34] Done evaluating on metric coco\n",
      "[02/10/2019 10:28:34] <<< Progress plot saved in trained_models/gkb_model//epoch_37.jpg >>>\n",
      "[02/10/2019 10:28:34] <<< Saving model to trained_models/gkb_model//epoch_37 ... >>>\n",
      "[02/10/2019 10:28:34] <<< Saving model_init to trained_models/gkb_model//epoch_37_structure_init.json... >>>\n",
      "[02/10/2019 10:28:34] <<< Saving model_next to trained_models/gkb_model//epoch_37_structure_next.json... >>>\n",
      "[02/10/2019 10:28:35] <<< Model saved >>>\n",
      "[02/10/2019 10:28:35] <<< Saving model to trained_models/gkb_model//epoch_37 ... >>>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[02/10/2019 10:28:35] <<< Saving model_init to trained_models/gkb_model//epoch_37_structure_init.json... >>>\n",
      "[02/10/2019 10:28:35] <<< Saving model_next to trained_models/gkb_model//epoch_37_structure_next.json... >>>\n",
      "[02/10/2019 10:28:36] <<< Model saved >>>\n",
      "[02/10/2019 10:41:49] WARNING: parallel loaders are not implemented\n",
      "[02/10/2019 10:41:49] <<< Predicting outputs of val set >>>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sampling 200/200  -  ETA: 2s   \n",
      " Total cost of the translations: 511.377123 \t Average cost of the translations: 2.556886\n",
      "The sampling took: 578.620402 secs (Speed: 2.893102 sec/sample)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[02/10/2019 10:51:28] Prediction output 0: target_text (text)\n",
      "[02/10/2019 10:51:28] Decoding beam search prediction ...\n",
      "[02/10/2019 10:51:28] Evaluating on metric coco\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[02/10/2019 10:51:38] Computing coco scores on the val split...\n",
      "[02/10/2019 10:51:38] Bleu_1: 0.679558721818\n",
      "[02/10/2019 10:51:38] Bleu_2: 0.510265956414\n",
      "[02/10/2019 10:51:38] Bleu_3: 0.401068534596\n",
      "[02/10/2019 10:51:38] Bleu_4: 0.325451556879\n",
      "[02/10/2019 10:51:38] CIDEr: 2.62620592378\n",
      "[02/10/2019 10:51:38] METEOR: 0.421383721325\n",
      "[02/10/2019 10:51:38] ROUGE_L: 0.5889599524\n",
      "[02/10/2019 10:51:38] TER: 0.533154121864\n",
      "[02/10/2019 10:51:38] Done evaluating on metric coco\n",
      "[02/10/2019 10:51:38] <<< Progress plot saved in trained_models/gkb_model//epoch_38.jpg >>>\n",
      "[02/10/2019 10:51:38] <<< Saving model to trained_models/gkb_model//epoch_38 ... >>>\n",
      "[02/10/2019 10:51:38] <<< Saving model_init to trained_models/gkb_model//epoch_38_structure_init.json... >>>\n",
      "[02/10/2019 10:51:38] <<< Saving model_next to trained_models/gkb_model//epoch_38_structure_next.json... >>>\n",
      "[02/10/2019 10:51:39] <<< Model saved >>>\n",
      "[02/10/2019 10:51:39] <<< Saving model to trained_models/gkb_model//epoch_38 ... >>>\n",
      "[02/10/2019 10:51:39] <<< Saving model_init to trained_models/gkb_model//epoch_38_structure_init.json... >>>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[02/10/2019 10:51:40] <<< Saving model_next to trained_models/gkb_model//epoch_38_structure_next.json... >>>\n",
      "[02/10/2019 10:51:40] <<< Model saved >>>\n",
      "[02/10/2019 11:11:27] WARNING: parallel loaders are not implemented\n",
      "[02/10/2019 11:11:27] <<< Predicting outputs of val set >>>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sampling 200/200  -  ETA: 5s   \n",
      " Total cost of the translations: 502.236009 \t Average cost of the translations: 2.511180\n",
      "The sampling took: 1150.568349 secs (Speed: 5.752842 sec/sample)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[02/10/2019 11:30:37] Prediction output 0: target_text (text)\n",
      "[02/10/2019 11:30:37] Decoding beam search prediction ...\n",
      "[02/10/2019 11:30:37] Evaluating on metric coco\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[02/10/2019 11:30:47] Computing coco scores on the val split...\n",
      "[02/10/2019 11:30:47] Bleu_1: 0.691289965261\n",
      "[02/10/2019 11:30:47] Bleu_2: 0.523946683254\n",
      "[02/10/2019 11:30:47] Bleu_3: 0.418913335001\n",
      "[02/10/2019 11:30:47] Bleu_4: 0.346204259485\n",
      "[02/10/2019 11:30:47] CIDEr: 2.76583625495\n",
      "[02/10/2019 11:30:47] METEOR: 0.429655889256\n",
      "[02/10/2019 11:30:47] ROUGE_L: 0.584038504635\n",
      "[02/10/2019 11:30:47] TER: 0.521804062127\n",
      "[02/10/2019 11:30:47] Done evaluating on metric coco\n",
      "[02/10/2019 11:30:48] <<< Progress plot saved in trained_models/gkb_model//epoch_39.jpg >>>\n",
      "[02/10/2019 11:30:48] <<< Saving model to trained_models/gkb_model//epoch_39 ... >>>\n",
      "[02/10/2019 11:30:48] <<< Saving model_init to trained_models/gkb_model//epoch_39_structure_init.json... >>>\n",
      "[02/10/2019 11:30:48] <<< Saving model_next to trained_models/gkb_model//epoch_39_structure_next.json... >>>\n",
      "[02/10/2019 11:30:48] <<< Model saved >>>\n",
      "[02/10/2019 11:30:48] <<< Saving model to trained_models/gkb_model//epoch_39 ... >>>\n",
      "[02/10/2019 11:30:48] <<< Saving model_init to trained_models/gkb_model//epoch_39_structure_init.json... >>>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[02/10/2019 11:30:49] <<< Saving model_next to trained_models/gkb_model//epoch_39_structure_next.json... >>>\n",
      "[02/10/2019 11:30:49] <<< Model saved >>>\n",
      "[02/10/2019 11:50:37] WARNING: parallel loaders are not implemented\n",
      "[02/10/2019 11:50:37] <<< Predicting outputs of val set >>>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sampling 200/200  -  ETA: 5s   \n",
      " Total cost of the translations: 457.194171 \t Average cost of the translations: 2.285971\n",
      "The sampling took: 1120.776313 secs (Speed: 5.603882 sec/sample)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[02/10/2019 12:09:18] Prediction output 0: target_text (text)\n",
      "[02/10/2019 12:09:18] Decoding beam search prediction ...\n",
      "[02/10/2019 12:09:18] Evaluating on metric coco\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[02/10/2019 12:09:28] Computing coco scores on the val split...\n",
      "[02/10/2019 12:09:28] Bleu_1: 0.691694246129\n",
      "[02/10/2019 12:09:28] Bleu_2: 0.524775284709\n",
      "[02/10/2019 12:09:28] Bleu_3: 0.41980716704\n",
      "[02/10/2019 12:09:28] Bleu_4: 0.348003238888\n",
      "[02/10/2019 12:09:28] CIDEr: 2.72000216084\n",
      "[02/10/2019 12:09:28] METEOR: 0.427255358166\n",
      "[02/10/2019 12:09:28] ROUGE_L: 0.587143033842\n",
      "[02/10/2019 12:09:28] TER: 0.519414575866\n",
      "[02/10/2019 12:09:28] Done evaluating on metric coco\n",
      "[02/10/2019 12:09:28] <<< Progress plot saved in trained_models/gkb_model//epoch_40.jpg >>>\n",
      "[02/10/2019 12:09:28] <<< Saving model to trained_models/gkb_model//epoch_40 ... >>>\n",
      "[02/10/2019 12:09:28] <<< Saving model_init to trained_models/gkb_model//epoch_40_structure_init.json... >>>\n",
      "[02/10/2019 12:09:28] <<< Saving model_next to trained_models/gkb_model//epoch_40_structure_next.json... >>>\n",
      "[02/10/2019 12:09:28] <<< Model saved >>>\n",
      "[02/10/2019 12:09:28] <<< Saving model to trained_models/gkb_model//epoch_40 ... >>>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[02/10/2019 12:09:29] <<< Saving model_init to trained_models/gkb_model//epoch_40_structure_init.json... >>>\n",
      "[02/10/2019 12:09:29] <<< Saving model_next to trained_models/gkb_model//epoch_40_structure_next.json... >>>\n",
      "[02/10/2019 12:09:30] <<< Model saved >>>\n",
      "[02/10/2019 12:29:26] WARNING: parallel loaders are not implemented\n",
      "[02/10/2019 12:29:26] <<< Predicting outputs of val set >>>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sampling 200/200  -  ETA: 3s   \n",
      " Total cost of the translations: 483.634846 \t Average cost of the translations: 2.418174\n",
      "The sampling took: 642.505807 secs (Speed: 3.212529 sec/sample)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[02/10/2019 12:40:08] Prediction output 0: target_text (text)\n",
      "[02/10/2019 12:40:08] Decoding beam search prediction ...\n",
      "[02/10/2019 12:40:08] Evaluating on metric coco\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[02/10/2019 12:40:18] Computing coco scores on the val split...\n",
      "[02/10/2019 12:40:18] Bleu_1: 0.685166699843\n",
      "[02/10/2019 12:40:18] Bleu_2: 0.519984522059\n",
      "[02/10/2019 12:40:18] Bleu_3: 0.415636605217\n",
      "[02/10/2019 12:40:18] Bleu_4: 0.342143583591\n",
      "[02/10/2019 12:40:18] CIDEr: 2.64304331198\n",
      "[02/10/2019 12:40:18] METEOR: 0.426717019119\n",
      "[02/10/2019 12:40:18] ROUGE_L: 0.588179791808\n",
      "[02/10/2019 12:40:18] TER: 0.52688172043\n",
      "[02/10/2019 12:40:18] Done evaluating on metric coco\n",
      "[02/10/2019 12:40:19] <<< Progress plot saved in trained_models/gkb_model//epoch_41.jpg >>>\n",
      "[02/10/2019 12:40:19] <<< Saving model to trained_models/gkb_model//epoch_41 ... >>>\n",
      "[02/10/2019 12:40:19] <<< Saving model_init to trained_models/gkb_model//epoch_41_structure_init.json... >>>\n",
      "[02/10/2019 12:40:19] <<< Saving model_next to trained_models/gkb_model//epoch_41_structure_next.json... >>>\n",
      "[02/10/2019 12:40:19] <<< Model saved >>>\n",
      "[02/10/2019 12:40:19] <<< Saving model to trained_models/gkb_model//epoch_41 ... >>>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[02/10/2019 12:40:20] <<< Saving model_init to trained_models/gkb_model//epoch_41_structure_init.json... >>>\n",
      "[02/10/2019 12:40:20] <<< Saving model_next to trained_models/gkb_model//epoch_41_structure_next.json... >>>\n",
      "[02/10/2019 12:40:21] <<< Model saved >>>\n",
      "[02/10/2019 12:53:34] WARNING: parallel loaders are not implemented\n",
      "[02/10/2019 12:53:34] <<< Predicting outputs of val set >>>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sampling 200/200  -  ETA: 2s   \n",
      " Total cost of the translations: 459.662535 \t Average cost of the translations: 2.298313\n",
      "The sampling took: 575.427510 secs (Speed: 2.877138 sec/sample)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[02/10/2019 13:03:09] Prediction output 0: target_text (text)\n",
      "[02/10/2019 13:03:09] Decoding beam search prediction ...\n",
      "[02/10/2019 13:03:09] Evaluating on metric coco\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[02/10/2019 13:03:19] Computing coco scores on the val split...\n",
      "[02/10/2019 13:03:19] Bleu_1: 0.689287843745\n",
      "[02/10/2019 13:03:19] Bleu_2: 0.525746259496\n",
      "[02/10/2019 13:03:19] Bleu_3: 0.422280246739\n",
      "[02/10/2019 13:03:19] Bleu_4: 0.34971151531\n",
      "[02/10/2019 13:03:19] CIDEr: 2.83239753749\n",
      "[02/10/2019 13:03:19] METEOR: 0.432545665635\n",
      "[02/10/2019 13:03:19] ROUGE_L: 0.59137112408\n",
      "[02/10/2019 13:03:19] TER: 0.520011947431\n",
      "[02/10/2019 13:03:19] Done evaluating on metric coco\n",
      "[02/10/2019 13:03:20] <<< Progress plot saved in trained_models/gkb_model//epoch_42.jpg >>>\n",
      "[02/10/2019 13:03:20] <<< Saving model to trained_models/gkb_model//epoch_42 ... >>>\n",
      "[02/10/2019 13:03:20] <<< Saving model_init to trained_models/gkb_model//epoch_42_structure_init.json... >>>\n",
      "[02/10/2019 13:03:20] <<< Saving model_next to trained_models/gkb_model//epoch_42_structure_next.json... >>>\n",
      "[02/10/2019 13:03:20] <<< Model saved >>>\n",
      "[02/10/2019 13:03:20] <<< Saving model to trained_models/gkb_model//epoch_42 ... >>>\n",
      "[02/10/2019 13:03:20] <<< Saving model_init to trained_models/gkb_model//epoch_42_structure_init.json... >>>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[02/10/2019 13:03:21] <<< Saving model_next to trained_models/gkb_model//epoch_42_structure_next.json... >>>\n",
      "[02/10/2019 13:03:21] <<< Model saved >>>\n",
      "[02/10/2019 13:16:34] WARNING: parallel loaders are not implemented\n",
      "[02/10/2019 13:16:34] <<< Predicting outputs of val set >>>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sampling 200/200  -  ETA: 2s   \n",
      " Total cost of the translations: 468.962443 \t Average cost of the translations: 2.344812\n",
      "The sampling took: 568.697257 secs (Speed: 2.843486 sec/sample)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[02/10/2019 13:26:03] Prediction output 0: target_text (text)\n",
      "[02/10/2019 13:26:03] Decoding beam search prediction ...\n",
      "[02/10/2019 13:26:03] Evaluating on metric coco\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[02/10/2019 13:26:13] Computing coco scores on the val split...\n",
      "[02/10/2019 13:26:13] Bleu_1: 0.693484654013\n",
      "[02/10/2019 13:26:13] Bleu_2: 0.536263541533\n",
      "[02/10/2019 13:26:13] Bleu_3: 0.434216711615\n",
      "[02/10/2019 13:26:13] Bleu_4: 0.363044046851\n",
      "[02/10/2019 13:26:13] CIDEr: 2.98936167149\n",
      "[02/10/2019 13:26:13] METEOR: 0.431860250306\n",
      "[02/10/2019 13:26:13] ROUGE_L: 0.604226751172\n",
      "[02/10/2019 13:26:13] TER: 0.503285543608\n",
      "[02/10/2019 13:26:13] Done evaluating on metric coco\n",
      "[02/10/2019 13:26:13] <<< Progress plot saved in trained_models/gkb_model//epoch_43.jpg >>>\n",
      "[02/10/2019 13:26:13] <<< Saving model to trained_models/gkb_model//epoch_43 ... >>>\n",
      "[02/10/2019 13:26:14] <<< Saving model_init to trained_models/gkb_model//epoch_43_structure_init.json... >>>\n",
      "[02/10/2019 13:26:14] <<< Saving model_next to trained_models/gkb_model//epoch_43_structure_next.json... >>>\n",
      "[02/10/2019 13:26:14] <<< Model saved >>>\n",
      "[02/10/2019 13:26:14] <<< Saving model to trained_models/gkb_model//epoch_43 ... >>>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[02/10/2019 13:26:14] <<< Saving model_init to trained_models/gkb_model//epoch_43_structure_init.json... >>>\n",
      "[02/10/2019 13:26:15] <<< Saving model_next to trained_models/gkb_model//epoch_43_structure_next.json... >>>\n",
      "[02/10/2019 13:26:15] <<< Model saved >>>\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-fa748ce52a5c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnmt_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/bayu/GTRLSTM-RDF-Extension_New/GTRLSTM-RDF/keras_wrapper/cnn_model.pyc\u001b[0m in \u001b[0;36mtrainNet\u001b[0;34m(self, ds, parameters, out_name)\u001b[0m\n\u001b[1;32m    738\u001b[0m             \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"<<< Training model >>>\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    739\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 740\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    741\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    742\u001b[0m         \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"<<< Finished training model >>>\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/bayu/GTRLSTM-RDF-Extension_New/GTRLSTM-RDF/keras_wrapper/cnn_model.pyc\u001b[0m in \u001b[0;36m__train\u001b[0;34m(self, ds, params, state)\u001b[0m\n\u001b[1;32m    929\u001b[0m                                      \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'n_parallel_loaders'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    930\u001b[0m                                      \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# params['n_parallel_loaders'],\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 931\u001b[0;31m                                      initial_epoch=params['epoch_offset'])\n\u001b[0m\u001b[1;32m    932\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    933\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__train_from_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/bayu/GTRLSTM-RDF-Extension_New/GTRLSTM-RDF/keras/legacy/interfaces.pyc\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     85\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     86\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 87\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/bayu/GTRLSTM-RDF-Extension_New/GTRLSTM-RDF/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   2247\u001b[0m                     outs = self.train_on_batch(x, y,\n\u001b[1;32m   2248\u001b[0m                                                \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2249\u001b[0;31m                                                class_weight=class_weight)\n\u001b[0m\u001b[1;32m   2250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2251\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/bayu/GTRLSTM-RDF-Extension_New/GTRLSTM-RDF/keras/engine/training.pyc\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1943\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1944\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1945\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1946\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1947\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/bayu/GTRLSTM-RDF-Extension_New/GTRLSTM-RDF/keras/backend/theano_backend.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   1300\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1301\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/bayu/anaconda2/envs/gtrlstm_extension/lib/python2.7/site-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    811\u001b[0m                         s.storage[0] = s.type.filter(\n\u001b[1;32m    812\u001b[0m                             \u001b[0marg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 813\u001b[0;31m                             allow_downcast=s.allow_downcast)\n\u001b[0m\u001b[1;32m    814\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    815\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/bayu/anaconda2/envs/gtrlstm_extension/lib/python2.7/site-packages/theano/tensor/type.pyc\u001b[0m in \u001b[0;36mfilter\u001b[0;34m(self, data, strict, allow_downcast)\u001b[0m\n\u001b[1;32m    115\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mallow_downcast\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m                 \u001b[0;31m# Convert to self.dtype, regardless of the type of data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtheano\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_asarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m                 \u001b[0;31m# TODO: consider to pad shape with ones to make it consistent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m                 \u001b[0;31m# with self.broadcastable... like vector->row type thing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/bayu/anaconda2/envs/gtrlstm_extension/lib/python2.7/site-packages/theano/misc/safe_asarray.pyc\u001b[0m in \u001b[0;36m_asarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtheano\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloatX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Convert into dtype object.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m     \u001b[0mrval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m     \u001b[0;31m# Note that dtype comparison must be done by comparing their `num`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0;31m# attribute. One cannot assume that two identical data types are pointers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/bayu/anaconda2/envs/gtrlstm_extension/lib/python2.7/site-packages/numpy/core/numeric.pyc\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m    529\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m     \"\"\"\n\u001b[0;32m--> 531\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    532\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "nmt_model.trainNet(dataset, training_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
